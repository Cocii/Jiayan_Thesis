{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imort Part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAINING OF THE U-net FOR INPAINTING AND SUPER-RESOLUTION\n",
    "\n",
    "1) Train, validate and test the U-net on the available datasets:\n",
    "    - Dataset_xf\n",
    "    - Dataset_yf\n",
    "    - Dataset_xy\n",
    "   Each 2D image is normalised by the maximum before testing.\n",
    "\n",
    "2) The Dataset is divided as follows:\n",
    "    - 80% Train set\n",
    "    - 10% Validation set\n",
    "    - 10% Test set\n",
    "\n",
    "2) Both the weights of the trained network and the loss history are\n",
    "   saved with pickle, in order to both retrain the network using the wiìeight \n",
    "   of last training and to visualize losses\n",
    "\n",
    "2) Compute and save the costum metrics as: nmse, psnr\n",
    "   both for couples:\n",
    "   - (ground truth,learned image)\n",
    "   - (ground truth, interpolated image)\n",
    "   To compare performances of the U-net with respect to a classic interpolator\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.special import boxcox\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import keras as keras\n",
    "import keras.callbacks as cb\n",
    "from keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from Model_Unet_complex import *\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from CustomMetricsLosses import *\n",
    "from scipy.interpolate import interp2d\n",
    "import argparse\n",
    "import os\n",
    "from random import sample\n",
    "from scipy.signal import resample\n",
    "\n",
    "# usa gpu con più memoria libera\n",
    "import GPUtil\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea sessione tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2175336065036621132\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7769907552\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5465371935379256778\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import clear_session\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=tf.compat.v1.ConfigProto()\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras(sess):\n",
    "\tclear_session()\n",
    "\tsess.close()\n",
    "\n",
    "def clip_normalize_power(in_content, mi, mx, p):\n",
    "    \"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for clipping\n",
    "    :param mx: max value for clipping\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized hard clipped image\n",
    "    \"\"\"\n",
    "    in_content = np.clip(in_content, a_min=mi, a_max=mx) #hard clip\n",
    "    in_content = 2 * (in_content - in_content.min()) / (in_content.max() - in_content.min()) - 1\n",
    "    in_content = np.power(np.abs(in_content), p)\n",
    "    return in_content\n",
    "\n",
    "def sigm_clip(in_content, mi, mx, p):\n",
    "    \"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for sigmoid function\n",
    "    :param mx: max value for sigmoid function\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized soft clipped image\n",
    "    \"\"\"\n",
    "    in_content =  mi + (mx-mi)*(lambda t: (1+300**(-t+0.5))**(-1) )( (in_content-mi)/(mx-mi) )  #sigmoid soft clip\n",
    "    in_content = 2 * (in_content - mi) / (mx - mi) - 1\n",
    "    in_content = np.power(np.abs(in_content), p)\n",
    "    return in_content\n",
    "\n",
    "def inv_sigm_clip(in_content, mi, mx, p):\n",
    "    \"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value used for inverting sigmoid\n",
    "    :param mx: max value used for inverting sigmoid\n",
    "    :param p: exponent for the power function (to be inverted)\n",
    "    :return: original image\n",
    "    \"\"\"\n",
    "    in_content = np.power(np.abs(in_content), 1/p)\n",
    "    #in_content = (in_content + 1) * (mx - mi) / 2 + mi\n",
    "    t = np.log((mx-mi)/(in_content-mi)-1)/np.log(300)\n",
    "    in_content = mi + (mx-mi)*(0.5-t)\n",
    "    return in_content\n",
    "\n",
    "def invertible_clipping(in_content, mi, mx, p):\n",
    "\t\"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for sigmoid function\n",
    "    :param mx: max value for sigmoid function\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized soft clipped image\n",
    "    \"\"\"\n",
    "\timage_clip = np.zeros(in_content.shape)\n",
    "    #Forward Clipping\n",
    "\ti,j = np.where(in_content < mi)\n",
    "\timage_clip[i, j] = 1e-4 * in_content[i, j] + (1 - 1e-4) * mi\n",
    "\ti,j = np.where(in_content > mx)\n",
    "\timage_clip[i, j] = 1e-4 * in_content[i, j] + (1 - 1e-4) * mx\n",
    "\ti,j = np.where((in_content >= mi) & (in_content <= mx))\n",
    "\timage_clip[i, j] = in_content[i, j]\n",
    "\n",
    "\t#Forward Normalization\n",
    "\t#real_mx = 1e-4 *1 + (1 - 1e-4) * mx\n",
    "\t#image_clip_norm = image_clip/real_mx\n",
    "\timage_clip_norm = 2 * (image_clip - mi) / (mx - mi) - 1\n",
    "\n",
    "\t#Forward Power\n",
    "\timage_clip_pow = np.power(np.abs(image_clip_norm), p)\n",
    "\treturn image_clip_pow\n",
    "\n",
    "def inv_invertible_clipping(in_content, mi, mx, p):\n",
    "\t#Backward Power\n",
    "\timage_inv_pow = np.power(np.abs(in_content), 1/p)\n",
    "\n",
    "\t#Backward Normalization\n",
    "\treal_mx = 1e-4 *1 + (1 - 1e-4) * mx\n",
    "\timage_inv_norm = image_inv_pow*real_mx\n",
    "\t#image_inv_norm = (image_inv_pow + 1) * (mx - mi) / 2 + mi\n",
    "\n",
    "\t#Backward Clipping\n",
    "\timage_inv = np.zeros(image_inv_norm.shape)\n",
    "\n",
    "\ti,j = np.where(image_inv_norm < mi)\n",
    "\timage_inv[i, j] = (image_inv_norm[i, j] - (1 - 1e-4) * mi) / 1e-4\n",
    "\ti,j = np.where(image_inv_norm > mx)\n",
    "\timage_inv[i, j] = (image_inv_norm[i, j] - (1 - 1e-4) * mx) / 1e-4\n",
    "\ti,j = np.where((image_inv_norm >= mi) & (image_inv_norm <= mx))\n",
    "\timage_inv[i, j] = image_inv_norm[i, j]\n",
    "\treturn image_inv\n",
    "\n",
    "def bc_clip(image, lam):\n",
    "    bc_image = boxcox(image, lam)\n",
    "    bc_min = bc_image.min()\n",
    "    bc_max = bc_image.max()\n",
    "    bc_image = (bc_image - bc_min) / (bc_max - bc_min)   \n",
    "    return (bc_image, bc_min, bc_max)\n",
    "\n",
    "def inv_bc_clip(image, mi, mx, lam):\n",
    "    bc_image = image * (mx - mi) + mi\n",
    "    bc_image = inv_boxcox(bc_image, lam)\n",
    "    return bc_image\n",
    "\n",
    "def normalize(in_content):\n",
    "\tin_content_abs = np.abs(in_content)\n",
    "\tin_content_norm = in_content_abs/in_content_abs.max()\n",
    "\treturn in_content_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Part(prepare&split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataset(imagetype,init,end,down_factor,snr_dB,downsampling,num_x_points,num_y_points,num_freqs):\n",
    "\n",
    "    x = np.arange(0,num_x_points,1).tolist()\n",
    "    y = np.arange(0,num_y_points,1).tolist()\n",
    "\n",
    "    images = []\n",
    "    zero_lines_idxs = []\n",
    "    counter_array = np.arange(init,end+1,1)\n",
    "\n",
    "    datapath = '../dataset/Dataset_complex/dataset_complex_'\n",
    "    for count in counter_array:\n",
    "        with open(datapath+str(count), 'rb') as data:\n",
    "            dati = pickle.load(data)\n",
    "\n",
    "        perc=10\n",
    "\n",
    "        print('')\n",
    "        print('Preparing '+datapath+str(count))\n",
    "        print('')\n",
    "\n",
    "        for i in range(len(dati)):\n",
    "            percentage= round((i/len(dati))*100,0)\n",
    "            if percentage==perc:\n",
    "                print('Percentage: '+str(perc)+'%')\n",
    "                perc = perc+10\n",
    "\n",
    "            target_img = np.array(dati[i][6])\n",
    "            input_img = np.array(dati[i][6])\n",
    "#             target_img = np.array(np.real(dati[i][6]))\n",
    "#             input_img = np.array(np.real(dati[i][6]))\n",
    "#             target_img = np.array(np.imag(dati[i][6]))\n",
    "#             input_img = np.array(np.imag(dati[i][6]))\n",
    "\n",
    "            #addition of noise\n",
    "            if snr_dB>0:\n",
    "                if i==0:\n",
    "                    print('')\n",
    "                    print('Adding '+str(snr_dB)+' dB noise to input images')\n",
    "                    print('')\n",
    "                power = np.mean(input_img ** 2)\n",
    "                var = power / (10 ** (snr_dB / 10))\n",
    "                noise = np.random.normal(0, np.sqrt(var), np.shape(input_img))\n",
    "                input_img = input_img+noise\n",
    "\n",
    "            if datapath=='./dataset/DatasetFiles/Dataset_xy/Dataset_xy_':\n",
    "                if downsampling=='random':\n",
    "                    if down_factor==2:\n",
    "                        x_sampled_list = sample(x,k=int(num_x_points*(1/down_factor)))\n",
    "\n",
    "                    else:\n",
    "                        if down_factor==4:\n",
    "                            x_sampled_list = sample(x,k=int(num_x_points*(2/down_factor)))\n",
    "                            y_sampled_list = sample(y,k=int(num_y_points*(2/down_factor)))\n",
    "\n",
    "                        else:\n",
    "                            x_sampled_list = sample(x,k=int(num_x_points*(2/down_factor)))\n",
    "                            y_sampled_list = sample(y,k=int(num_y_points*(4/down_factor)))\n",
    "\n",
    "                        y_sampled_list.sort()\n",
    "\n",
    "                    x_sampled_list.sort()\n",
    "\n",
    "                    if down_factor==2:\n",
    "                        sampled_list = x_sampled_list\n",
    "                        i=0\n",
    "                        for idx in x:\n",
    "                            if i==num_x_points*(1/down_factor):\n",
    "                                break\n",
    "                            elif idx!=sampled_list[i]:\n",
    "                                input_img[:,idx]=np.zeros(num_y_points)\n",
    "                            else:\n",
    "                                i=i+1\n",
    "                    else:\n",
    "                        sampled_list = x_sampled_list+y_sampled_list\n",
    "                        x_down_factor=down_factor/2\n",
    "\n",
    "                        i=0\n",
    "\n",
    "                        for idx in x:\n",
    "                            if i==int(num_x_points*(1/x_down_factor)):\n",
    "                                break\n",
    "                            elif idx!=sampled_list[i]:\n",
    "                                input_img[:,idx]=np.zeros(num_y_points)\n",
    "                            else:\n",
    "                                i=i+1\n",
    "                        for idy in y:\n",
    "                            if i==len(sampled_list):\n",
    "                                break\n",
    "                            elif idy!=sampled_list[i]:\n",
    "                                input_img[idy,:]=np.zeros(num_x_points)\n",
    "                            else:\n",
    "                                i=i+1\n",
    "\n",
    "                elif downsampling=='regular':\n",
    "\n",
    "                    if down_factor==2:\n",
    "                        sampled_list = x[::down_factor]\n",
    "\n",
    "                        for idx in x:\n",
    "                            if idx%down_factor!=0:\n",
    "                                input_img[:,idx]=np.zeros(num_y_points)\n",
    "\n",
    "                    else:\n",
    "                        x_down_factor = int(down_factor/2)\n",
    "                        if down_factor==4:\n",
    "                            y_down_factor = x_down_factor\n",
    "                            sampled_list = x[::x_down_factor]+y[::y_down_factor]\n",
    "                        else:\n",
    "                            y_down_factor = int(x_down_factor/2)\n",
    "                            sampled_list = x[::x_down_factor]+y[::y_down_factor]\n",
    "\n",
    "                        for idx in x:\n",
    "                            if idx%x_down_factor!=0:\n",
    "                                input_img[:,idx]=np.zeros(num_y_points)\n",
    "\n",
    "                        for idy in y:\n",
    "                            if idy%y_down_factor==0:\n",
    "                                input_img[idy,:]=np.zeros(num_x_points)\n",
    "\n",
    "                #print(sampled_list)\n",
    "\n",
    "            elif datapath=='./dataset/DatasetFiles/Dataset_yf/Dataset_yf_':\n",
    "                if downsampling=='random':\n",
    "                    sampled_list = sample(y,k=int(num_y_points*(1-1/down_factor)))\n",
    "                    sampled_list.sort()\n",
    "                    i=0\n",
    "                    for idx in y:\n",
    "                        if i==len(sampled_list):\n",
    "                            break\n",
    "                        elif idx==sampled_list[i]:\n",
    "                            input_img[idx,:]=np.zeros(num_freqs)\n",
    "                            i=i+1\n",
    "                elif downsampling=='regular':\n",
    "                    for idy in y:\n",
    "                        if idy%down_factor!=0:\n",
    "                            input_img[idy,:]=np.zeros(num_freqs)\n",
    "\n",
    "#             elif datapath=='./dataset/DatasetFiles/Dataset_xf/Dataset_xf_':\n",
    "            else:\n",
    "\n",
    "                if num_x_points<64: #it means the image is real\n",
    "                    target_img = np.array(dati[i][6][16:16+32,:])\n",
    "                    input_img = np.array(dati[i][6][16:16+32,:])\n",
    "\n",
    "                if downsampling=='random':\n",
    "                    sampled_list = sample(x,k=int(num_x_points*(1/down_factor)))\n",
    "                    sampled_list.sort()\n",
    "\n",
    "                    i=0\n",
    "                    for idx in x:\n",
    "                        if i==num_x_points*(1/down_factor):\n",
    "                            break\n",
    "                        elif idx!=sampled_list[i]:\n",
    "                            input_img[idx,:]=np.zeros(num_freqs)\n",
    "                        else:\n",
    "                            i=i+1\n",
    "\n",
    "                elif downsampling=='regular':\n",
    "                    sampled_list = x[::down_factor]\n",
    "\n",
    "                    for idx in x:\n",
    "                        if idx%down_factor!=0:\n",
    "                            input_img[idx,:]=np.zeros(num_freqs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             if imagetype!='xy' and abs(np.mean(target_img**2))>1e-10:\n",
    "            if imagetype!='xy':\n",
    "#                 print(\"np.mean(target_img**2)==\",np.mean(target_img**2))\n",
    "                images.append((input_img,target_img))\n",
    "                zero_lines_idxs.append(sampled_list)\n",
    "\n",
    "                '''plt.subplot(121), plt.title('Input xy image')\n",
    "                plt.imshow(input_img, cmap='bone', aspect='auto'), plt.colorbar()\n",
    "                plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "                plt.grid(None)\n",
    "                plt.subplot(122), plt.title('Target xy image')\n",
    "                plt.imshow(target_img, cmap='bone', aspect='auto'), plt.colorbar()\n",
    "                plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "                plt.grid(None)\n",
    "                plt.show()'''\n",
    "\n",
    "    ### ADD CHANNEL DIMENSION\n",
    "\n",
    "    print('')\n",
    "    print('Dataset ready to be splitted --> '+str(len(images))+' images')\n",
    "    print('')\n",
    "\n",
    "    images = np.array(images)\n",
    "    if datapath=='./dataset/DatasetFiles/Dataset_xf/Dataset_xf_':\n",
    "        images = images.reshape(len(images),2,num_x_points,num_freqs,1)\n",
    "    elif datapath=='./dataset/DatasetFiles/Dataset_yf/Dataset_yf_':\n",
    "        images = images.reshape(len(images),2,num_y_points,num_freqs,1)\n",
    "    elif datapath=='./dataset/DatasetFiles/Dataset_xy/Dataset_xy_':\n",
    "        images = images.reshape(len(images),2,num_y_points,num_x_points,1)\n",
    "    else:\n",
    "        images = images.reshape(len(images),2,num_x_points,num_freqs,1)\n",
    "    return images, zero_lines_idxs\n",
    "\n",
    "def splitDataset(dataset,zero_lines_idxs,batch_size,lam):\n",
    "    ### DIVIDING THE DATASET INTO TRAIN, VALIDATION AND TEST SETS\n",
    "    shuffler = np.random.permutation(len(dataset))\n",
    "    print(dataset.shape)\n",
    "    if isinstance(dataset[0][1][0][0][0], complex):\n",
    "        real = np.real(dataset)\n",
    "        imag = np.imag(dataset)\n",
    "        dataset = np.stack((real[:], imag[:]), axis=4)\n",
    "        print(dataset.shape) \n",
    "\n",
    "    dataset = np.array(dataset, dtype='float32')\n",
    "    zero_lines_idxs = np.array(zero_lines_idxs)\n",
    "\n",
    "    dataset = dataset[shuffler]\n",
    "    zero_lines_idxs = zero_lines_idxs[shuffler]\n",
    "\n",
    "    train, val, test = np.split(dataset,[int(.8 * len(dataset)),int(.9 * len(dataset))])\n",
    "    train_zli, val_zli, test_zli = np.split(zero_lines_idxs,[int(.8 * len(zero_lines_idxs)),int(.9 * len(zero_lines_idxs))])\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "\n",
    "    print(\"Preparing training set \")\n",
    "    train_samples = len(train)-len(train)%batch_size\n",
    "    for idx in range(train_samples):\n",
    "        '''input_img_eq, mini, maxi = bc_clip(train[idx][0],lam)\n",
    "        target_img_eq, mint, maxt = bc_clip(train[idx][1],lam)'''\n",
    "        X_train.append(normalize(train[idx][0]))\n",
    "        Y_train.append(normalize(train[idx][1]))\n",
    "        '''X_train.append(input_img_eq)\n",
    "        Y_train.append(target_img_eq)'''\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "\n",
    "    print(\"Training sets ready :\"+str(np.shape(X_train)))\n",
    "    print('')\n",
    "\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "\n",
    "    print(\"Preparing validation set \")\n",
    "    val_samples = len(val)-len(val)%batch_size\n",
    "    for idx in range(val_samples):\n",
    "        '''input_img_eq, mini, maxi = bc_clip(val[idx][0],lam)\n",
    "        target_img_eq, mint, maxt = bc_clip(val[idx][1],lam)'''\n",
    "        X_val.append(normalize(val[idx][0]))\n",
    "        Y_val.append(normalize(val[idx][1]))\n",
    "        '''X_val.append(input_img_eq)\n",
    "        Y_val.append(target_img_eq)'''\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    Y_val = np.array(Y_val)\n",
    "\n",
    "    print(\"Validation set ready :\"+str(np.shape(X_val)))\n",
    "    print('')\n",
    "\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    X_test_noeq = []\n",
    "    Y_test_noeq = []\n",
    "    dynamics = []\n",
    "\n",
    "    print(\"Preparing test set \")\n",
    "    test_samples = len(test)-len(test)%batch_size\n",
    "    for idx in range(test_samples):\n",
    "        '''input_img_eq, mini, maxi = bc_clip(test[idx][0],lam)\n",
    "        target_img_eq, mint, maxt = bc_clip(test[idx][1],lam)'''\n",
    "        X_test.append(normalize(test[idx][0]))\n",
    "        Y_test.append(normalize(test[idx][1]))\n",
    "        '''X_test_noeq.append(test[idx][0])\n",
    "        Y_test_noeq.append(test[idx][1])\n",
    "        #dynamics.append((maxt,mint))'''\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(Y_test)\n",
    "    '''X_test_noeq = np.array(X_test_noeq)\n",
    "    Y_test_noeq = np.array(Y_test_noeq)\n",
    "    dynamics = np.array(dynamics)'''\n",
    "\n",
    "    print(\"Test set ready :\"+str(np.shape(X_test)))\n",
    "    print('')\n",
    "\n",
    "    #return X_train,Y_train,X_val,Y_val,X_test,Y_test,X_test_noeq,Y_test_noeq,dynamics\n",
    "    return X_train,Y_train,X_val,Y_val,X_test,Y_test,test_zli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial part (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing ../dataset/Dataset_complex/dataset_complex_1\n",
      "\n",
      "Percentage: 10%\n",
      "Percentage: 20%\n",
      "Percentage: 30%\n",
      "Percentage: 40%\n",
      "Percentage: 50%\n",
      "Percentage: 60%\n",
      "Percentage: 70%\n",
      "Percentage: 80%\n",
      "Percentage: 90%\n",
      "Percentage: 100%\n",
      "\n",
      "Dataset ready to be splitted --> 1632 images\n",
      "\n",
      "(1632, 2, 64, 1024, 1)\n",
      "(1632, 2, 64, 1024, 2, 1)\n",
      "Preparing training set \n",
      "Training sets ready :(1305, 64, 1024, 2, 1)\n",
      "\n",
      "Preparing validation set \n",
      "Validation set ready :(163, 64, 1024, 2, 1)\n",
      "\n",
      "Preparing test set \n",
      "Test set ready :(164, 64, 1024, 2, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    ".py args：\n",
    "\n",
    "\"\"\"\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--imagetype',type=str,required=False,default='yf')\n",
    "# parser.add_argument('--outdir',type=str,required=False,\n",
    "#     default='../ModelCheckpoint/super_res_imag_xf_2.h5')\n",
    "# parser.add_argument('--outdir_trainhistory',type=str,required=False,\n",
    "#     default='../ModelCheckpoint/th_imag_xf_2')\n",
    "# parser.add_argument('--outdir_metrics',type=str,required=False,\n",
    "#     default='../Metrics/Metrics_behaviour_imag_xf_2')\n",
    "# parser.add_argument('--outdir_plots',type=str,required=False,\n",
    "#     default='../Plots/Plot_imag_xf_2')\n",
    "# parser.add_argument('--lam',type=float,required=False,default=0.3)\n",
    "# parser.add_argument('--downsampling',type=str,required=False,\n",
    "#     default='regular')\n",
    "# parser.add_argument('--lr',type=float,required=False,default=0.0004)\n",
    "# parser.add_argument('--num_freqs',type=int,required=False,default=1024)\n",
    "# parser.add_argument('--snr',type=int,required=False,default=0)\n",
    "# parser.add_argument('--batch_size',type=int,required=False,default=1)\n",
    "# parser.add_argument('--num_x_points',type=int,required=False,default=64)\n",
    "# parser.add_argument('--num_y_points',type=int,required=False,default=16)\n",
    "# parser.add_argument('--epochs',type=int,required=False,default=1)\n",
    "# parser.add_argument('--down_factor',type=int,required=False,default=8)\n",
    "# parser.add_argument('--train_session',type=int,required=False,default=1)\n",
    "# parser.add_argument('--init_dataset_idx',type=int,required=False,default=1)\n",
    "# parser.add_argument('--final_dataset_idx',type=int,required=False,default=1)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ".ipynb args：\n",
    "\n",
    "\"\"\"\n",
    "args = easydict.EasyDict({\n",
    "    \"imagetype\": 'xf',\n",
    "    \"outdir\": '../ModelCheckpoint/super_res_imag_xf_2.h5',\n",
    "    \"outdir_trainhistory\": '../ModelCheckpoint/th_imag_xf_2',\n",
    "    \"outdir_metrics\": '../Metrics/Metrics_behaviour_imag_xf_2',\n",
    "    \"outdir_plots\": '../Plots/Plot_imag_xf_2',\n",
    "    \"lam\": 0.3,\n",
    "    \"downsampling\": 'regular',\n",
    "    \"lr\": 0.0004,\n",
    "    \"num_freqs\": 1024,\n",
    "    \"snr\": 0,\n",
    "    \"batch_size\": 1,\n",
    "    \"num_x_points\": 64,\n",
    "    \"num_y_points\": 16,\n",
    "    \"epochs\": 1,\n",
    "    \"down_factor\": 2,\n",
    "    \"train_session\": 1,      # 1 2 3\n",
    "    \"init_dataset_idx\": 1,   # 1 5 8\n",
    "    \"final_dataset_idx\": 1   # 4 7 10\n",
    "})\n",
    "\n",
    "\n",
    "#inizializza variabili globali\n",
    "num_x_points = args.num_x_points\n",
    "num_y_points = args.num_y_points\n",
    "num_freqs = args.num_freqs\n",
    "x = np.arange(0,num_x_points,1).tolist() # x-axis\n",
    "y = np.arange(0,num_y_points,1).tolist() # y-axis\n",
    "freq = np.arange(0,num_freqs,1).tolist()  #frequency axis\n",
    "\n",
    "dataset,zero_lines_idxs = prepareDataset(args.imagetype,args.init_dataset_idx,args.final_dataset_idx,args.down_factor,args.snr,args.downsampling, \n",
    "    num_x_points, num_y_points, num_freqs)\n",
    "# dataset[image_num][0downsmaplling][x/y numbers]\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test,test_zli = splitDataset(dataset,zero_lines_idxs,args.batch_size,args.lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compile model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model\n",
      "\n",
      "=====================first_dim: 64 =====================second_dim: 1024\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 1024, 2) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d (Reflectio (None, 66, 1026, 2)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 1024, 16) 304         reflection_padding2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 1024, 16) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_1 (Reflect (None, 66, 1026, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 1024, 16) 2320        reflection_padding2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 1024, 16) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 512, 16)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_2 (Reflect (None, 34, 514, 16)  0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 512, 32)  4640        reflection_padding2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 512, 32)  128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_3 (Reflect (None, 34, 514, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 512, 32)  9248        reflection_padding2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 512, 32)  128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 256, 32)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_4 (Reflect (None, 18, 258, 32)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 256, 64)  18496       reflection_padding2d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 256, 64)  64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_5 (Reflect (None, 18, 258, 64)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 256, 64)  36928       reflection_padding2d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 256, 64)  64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 128, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_6 (Reflect (None, 10, 130, 64)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 128, 128)  73856       reflection_padding2d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 128, 128)  32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_7 (Reflect (None, 10, 130, 128) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 128, 128)  147584      reflection_padding2d_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 128, 128)  32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 64, 128)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 64, 256)   295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 64, 256)   16          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 64, 256)   590080      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 64, 256)   16          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 128, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 128, 384)  0           up_sampling2d[0][0]              \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_8 (Reflect (None, 10, 130, 384) 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 128, 128)  442496      reflection_padding2d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 128, 128)  32          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_9 (Reflect (None, 10, 130, 128) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 128, 128)  147584      reflection_padding2d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 128, 128)  32          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 256, 128) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 256, 192) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_10 (Reflec (None, 18, 258, 192) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 256, 64)  110656      reflection_padding2d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 256, 64)  64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_11 (Reflec (None, 18, 258, 64)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 256, 64)  36928       reflection_padding2d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 256, 64)  64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 512, 64)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 512, 96)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_12 (Reflec (None, 34, 514, 96)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 512, 32)  27680       reflection_padding2d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 512, 32)  128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_13 (Reflec (None, 34, 514, 32)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 512, 32)  9248        reflection_padding2d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 512, 32)  128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 1024, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 1024, 48) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_14 (Reflec (None, 66, 1026, 48) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 1024, 16) 6928        reflection_padding2d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 1024, 16) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_15 (Reflec (None, 66, 1026, 16) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 1024, 16) 2320        reflection_padding2d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 1024, 16) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 1024, 2)  34          batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,964,450\n",
      "Trainable params: 1,963,474\n",
      "Non-trainable params: 976\n",
      "__________________________________________________________________________________________________\n",
      "Model compiled. Training model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"Compiling model\")\n",
    "    print('')\n",
    "    # Build&Compile Neural Networks\n",
    "    if args.imagetype=='xf':\n",
    "        uNet = uNet1(num_x_points,num_freqs)\n",
    "    elif args.imagetype=='yf':\n",
    "        uNet = uNet1(num_y_points,num_freqs)\n",
    "    else:\n",
    "        uNet = uNet1(num_y_points,num_x_points)\n",
    "\n",
    "    uNet.summary()\n",
    "\n",
    "    if args.train_session>1:\n",
    "        print('Loading weights')\n",
    "        uNet.load_weights(args.outdir)\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "    if args.imagetype=='xy':\n",
    "        uNet.compile(loss=mse, optimizer=opt, metrics=[NMSE, ncc])\n",
    "    elif args.imagetype=='xf':\n",
    "        uNet.compile(loss=mask_mse(args.batch_size,args.num_x_points), optimizer=opt, metrics=[NMSE, ncc])\n",
    "    elif args.imagetype=='yf':\n",
    "        uNet.compile(loss=mask_mse(args.batch_size,args.num_y_points), optimizer=opt, metrics=[NMSE, ncc])\n",
    "\n",
    "    callback = [#EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.2),\n",
    "                ModelCheckpoint(\n",
    "                    filepath=args.outdir,\n",
    "                    monitor='val_loss', verbose=1, save_best_only=True)]\n",
    "\n",
    "    print(\"Model compiled. Training model\")\n",
    "    print('')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Test\n",
    "# import math\n",
    "# # print(np.shape(dataset))\n",
    "# # print(np.shape(X_train))\n",
    "# # print(np.shape(dataset[0][1][0]))\n",
    "# # test_num =  dataset[0][1][1]\n",
    "# # print(np.shape(test_num))\n",
    "# # print(test_num)\n",
    "# # print(isinstance(dataset[0][1][0][0][0], complex))\n",
    "# # print(dataset[0][1][0][0][0])\n",
    "\n",
    "\n",
    "# # if isinstance(dataset[0][1][0][0][0], complex):\n",
    "# #     for i in range(64):\n",
    "# #         for j in range(1024):\n",
    "# #             dataset[0][1][i][j][1] = np.imag(dataset[0][1][i][j][0])\n",
    "# #             dataset[0][1][i][j][0] = np.real(dataset[0][1][i][j][0])\n",
    "# # dataset[0][1][0][0].append([np.imag(dataset[0][1][0][0][0])])\n",
    "# # array = np.concatenate((np.imag(dataset[0][1][0][0][0]), dataset[0][1][0][0][0]), axis=1)\n",
    "\n",
    "# print(dataset[0][1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# real = np.real(dataset)\n",
    "# imag = np.imag(dataset)\n",
    "\n",
    "\n",
    "# print(np.shape(dataset))\n",
    "# print(np.shape(real))\n",
    "# result = np.stack((real[:], imag[:]), axis=4)\n",
    "# print(result.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(real[0][0][0][0][0])\n",
    "# print(imag[0][0][0][0][0])\n",
    "# print(result[0][0][0][0][0][0],\" \",result[0][0][0][0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the U-net model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mask_mse.<locals>.loss at 0x7f53c8535f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function mask_mse.<locals>.loss at 0x7f53c8535f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1305/1305 [==============================] - 70s 21ms/step - loss: 5.3365e-04 - NMSE: -10.2313 - ncc: 0.8348 - val_loss: 7.6568e-06 - val_NMSE: -30.0291 - val_ncc: 0.9845\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00001, saving model to ../ModelCheckpoint/super_res_imag_xf_2.h5\n",
      "{'name': 'reflection_padding2d', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_1', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_2', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_3', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_4', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_5', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_6', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_7', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_8', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_9', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_10', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_11', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_12', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_13', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_14', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_15', 'trainable': True, 'dtype': 'float32'}\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\t### TRAINING THE U-net\n",
    "\n",
    "\thistory = uNet.fit(X_train, Y_train, epochs=args.epochs, verbose=1, callbacks=callback, validation_data=(X_val, Y_val),batch_size=args.batch_size)\n",
    "\n",
    "\twith open(args.outdir_trainhistory, 'wb') as file_pi:\n",
    "\t\tpickle.dump(history.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 7.5619e-06 - NMSE: -29.9613 - ncc: 0.9843\n",
      "164/164 [==============================] - 1s 6ms/step\n",
      "score: [7.561886377516203e-06, -29.961280822753906, 0.9843343496322632]\n",
      "\n",
      "Custom metrics and plot results\n"
     ]
    }
   ],
   "source": [
    "### TESTING THE U-net\n",
    "print('')\n",
    "print(\"Testing\")\n",
    "score = uNet.evaluate(X_test, Y_test, verbose=1, batch_size=args.batch_size)\n",
    "probs = uNet.predict(X_test, verbose=1, batch_size=args.batch_size)\n",
    "print(\"score:\",score)\n",
    "print('')\n",
    "print(\"Custom metrics and plot results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate custom matrics and save them using pickle (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.complex128' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 32\u001b[0m\n\u001b[1;32m     25\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m probs[idx][:,:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m probs[idx][:,:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39mj\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#         print(\"down shape: \",np.shape(down))\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#         print(\"prediction shape: \",np.shape(prediction))\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#         ground_truth = Y_test[idx][:,:,:,0] # complex \u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#         prediction = probs[idx][:] # complex\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#         print(np.shape(probs))\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#         print(np.shape(ground_truth),\" \",np.shape(prediction))\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     nmse1 \u001b[38;5;241m=\u001b[39m \u001b[43mnmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     ncc1 \u001b[38;5;241m=\u001b[39m NCC(ground_truth,prediction)\n\u001b[1;32m     35\u001b[0m     zero_row_idxs \u001b[38;5;241m=\u001b[39m test_zli[idx]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.complex128' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "    ### CALCULATE THE CUSTOM METRICS AND SAVE THEM USING PICKLE\n",
    "\n",
    "    if args.imagetype=='xy':\n",
    "        if args.down_factor==2:\n",
    "            x_ds = np.arange(0,num_x_points,args.down_factor) # down-sampled x-axis vector\n",
    "            y_ds = y\n",
    "        elif args.down_factor==4:\n",
    "            x_ds = np.arange(0,num_x_points,int(args.down_factor/2)) \n",
    "            y_ds = np.arange(0,num_y_points,int(args.down_factor/2))\n",
    "        else:\n",
    "            x_ds = np.arange(0,num_x_points,int(args.down_factor/2)) \n",
    "            y_ds = np.arange(0,num_y_points,int(args.down_factor/4))\n",
    "    else:\n",
    "        x_ds = np.arange(0,num_x_points,args.down_factor)\n",
    "        y_ds = np.arange(0,num_y_points,args.down_factor)\n",
    "\n",
    "    list_metrics = []\n",
    "    list_plots = []\n",
    "#     print(\"X_test shape: \",np.shape(X_test))\n",
    "#     print(\"Y_test shape: \",np.shape(Y_test))\n",
    "#     print(\"probs shape: \",np.shape(probs))\n",
    "    for idx in range(len(Y_test)):\n",
    "        down = X_test[idx][:,:,0,0] + X_test[idx][:,:,1,0]*1j\n",
    "        ground_truth = Y_test[idx][:,:,0,0] + Y_test[idx][:,:,1,0]*1j\n",
    "        prediction = probs[idx][:,:,0] + probs[idx][:,:,1]*1j\n",
    "#         print(\"down shape: \",np.shape(down))\n",
    "#         print(\"prediction shape: \",np.shape(prediction))\n",
    "#         ground_truth = Y_test[idx][:,:,:,0] # complex \n",
    "#         prediction = probs[idx][:] # complex\n",
    "#         print(np.shape(probs))\n",
    "#         print(np.shape(ground_truth),\" \",np.shape(prediction))\n",
    "        nmse1 = nmse(ground_truth,prediction)\n",
    "        ncc1 = NCC(ground_truth,prediction)\n",
    "\n",
    "        zero_row_idxs = test_zli[idx]\n",
    "\n",
    "        if args.imagetype=='xy':\n",
    "            if args.downsampling=='random':\n",
    "\n",
    "                if args.down_factor==2:\n",
    "                    ds_image = np.zeros((num_y_points,int(num_x_points/args.down_factor)))\n",
    "\n",
    "                    zero_row_idx=0\n",
    "                    count=0\n",
    "\n",
    "                    for j in x:\n",
    "                        if j==zero_row_idxs[zero_row_idx]:\n",
    "                            ds_image[:,count] = down[:,j]\n",
    "                            count=count+1\n",
    "                            zero_row_idx=zero_row_idx+1\n",
    "                        if zero_row_idx==num_x_points*(1/args.down_factor):\n",
    "                            break\n",
    "\n",
    "                else:\n",
    "                    x_ds_image = np.zeros((num_y_points,2*int(num_x_points/args.down_factor)))\n",
    "\n",
    "                    zero_row_idx=0\n",
    "                    count=0\n",
    "\n",
    "                    for j in x:\n",
    "                        if j==zero_row_idxs[zero_row_idx]:\n",
    "                            x_ds_image[:,count] = down[:,j]\n",
    "                            count=count+1\n",
    "                            zero_row_idx=zero_row_idx+1\n",
    "                        if zero_row_idx==num_x_points*(2/args.down_factor):\n",
    "                            break\n",
    "\n",
    "                    count=0\n",
    "\n",
    "                    if args.down_factor==4:\n",
    "                        ds_image = np.zeros((2*int(num_y_points/args.down_factor),2*int(num_x_points/args.down_factor)))\n",
    "\n",
    "                    elif args.down_factor==8:\n",
    "                        ds_image = np.zeros((4*int(num_y_points/args.down_factor),2*int(num_x_points/args.down_factor)))\n",
    "\n",
    "                    for i in y:\n",
    "                        if i==zero_row_idxs[zero_row_idx]:\n",
    "                            ds_image[count,:] = x_ds_image[i,:]\n",
    "                            count=count+1\n",
    "                            zero_row_idx=zero_row_idx+1\n",
    "                        if zero_row_idx==len(zero_row_idxs):\n",
    "                            break\n",
    "\n",
    "            elif args.downsampling=='regular':\n",
    "                if args.down_factor==8:\n",
    "                    ds_image = ground_truth[::int(args.down_factor/4),::int(args.down_factor/2)]\n",
    "                elif args.down_factor==4:\n",
    "                    ds_image = ground_truth[::int(args.down_factor/2),::int(args.down_factor/2)]\n",
    "                else:\n",
    "                    ds_image = ground_truth[:,::args.down_factor]\n",
    "\n",
    "            '''interp = interp2d(x_ds, y_ds, ds_image, kind='cubic')\n",
    "            interp_image = interp(x,y)'''\n",
    "            interp_y = resample(ds_image,num_y_points,axis=0)\n",
    "            interp_image = resample(interp_y,num_x_points,axis=1)\n",
    "\n",
    "        elif args.imagetype=='xf':\n",
    "\n",
    "            if args.downsampling=='random':\n",
    "\n",
    "                ds_image = np.zeros((int(num_x_points/args.down_factor),num_freqs))\n",
    "\n",
    "                zero_row_idx=0\n",
    "                count=0\n",
    "\n",
    "                for j in x:\n",
    "                    if j==zero_row_idxs[zero_row_idx]:\n",
    "                        ds_image[count,:] = down[j,:]\n",
    "                        count=count+1\n",
    "                        zero_row_idx=zero_row_idx+1\n",
    "                    if zero_row_idx==num_x_points*(1/args.down_factor):\n",
    "                        break\n",
    "\n",
    "            elif args.downsampling=='regular':\n",
    "                    ds_image = ground_truth[::args.down_factor,:]\n",
    "\n",
    "            '''interp = interp2d(freq, x_ds, ds_image, kind='cubic')\n",
    "            interp_image = interp(freq,x)'''\n",
    "            interp_image = resample(ds_image,num_x_points,axis=0)\n",
    "\n",
    "# \t\t\tplt.subplot(141), plt.title('Target')\n",
    "# \t\t\tplt.imshow(np.clip(ground_truth, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# \t\t\tplt.xlabel('Freq [Hz]'), plt.ylabel('X [m]')\n",
    "# \t\t\tplt.grid(None)\n",
    "# \t\t\tplt.subplot(142), plt.title('U-net input')\n",
    "# \t\t\tplt.imshow(np.clip(down, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# \t\t\tplt.xlabel('Freq [Hz]')\n",
    "# \t\t\tplt.grid(None)\n",
    "# \t\t\tplt.subplot(143), plt.title('Interp input')\n",
    "# \t\t\tplt.imshow(np.clip(ds_image, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# \t\t\tplt.xlabel('Freq [Hz]')\n",
    "# \t\t\tplt.grid(None)\n",
    "# \t\t\tplt.subplot(144), plt.title('Interp output')\n",
    "# \t\t\tplt.imshow(np.clip(interp_image, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# \t\t\tplt.xlabel('Freq [Hz]')\n",
    "# \t\t\tplt.grid(None)\n",
    "# \t\t\tplt.show()\n",
    "\n",
    "        elif args.imagetype=='yf':\n",
    "            if args.downsampling=='random':\n",
    "                ds_image=down[~np.all(down==0, axis=1)]\n",
    "\n",
    "                if len(ds_image)==num_y_points/args.down_factor-2:\n",
    "                    ds_image = np.concatenate((np.zeros((1,num_freqs)),ds_image), 0)\n",
    "                    ds_image = np.concatenate((ds_image,np.zeros((1,num_freqs))), 0)\n",
    "\n",
    "                elif len(ds_image)==num_y_points/args.down_factor-1:\n",
    "                    if np.max(ground_truth[0,:])==0:\n",
    "                        ds_image = np.concatenate((np.zeros((1,num_freqs)),ds_image), 0)\n",
    "\n",
    "                    elif np.max(ground_truth[num_y_points-1,:])==0:\n",
    "                        ds_image = np.concatenate((ds_image,np.zeros((1,num_freqs))), 0)\n",
    "\n",
    "            elif args.downsampling=='regular':\n",
    "                ds_image = ground_truth[::args.down_factor,:]\n",
    "\n",
    "            '''interp = interp2d(freq, y_ds, ds_image, kind='cubic')\n",
    "            interp_image = interp(freq,y)'''\n",
    "            interp_image = resample(ds_image,num_y_points,axis=0)\n",
    "\n",
    "        nmse2 = nmse(ground_truth,interp_image)\n",
    "        ncc2 = NCC(ground_truth,interp_image)\n",
    "        if args.snr>0:\n",
    "            list_metrics.append((nmse1,ncc1))\n",
    "            list_plots.append((down,ground_truth,prediction))\n",
    "        else:\n",
    "            list_metrics.append((nmse1,nmse2,ncc1,ncc2))\n",
    "            if idx<50:\n",
    "                list_plots.append((down,ground_truth,prediction,interp_image))\n",
    "\n",
    "    with open(args.outdir_metrics,'wb') as output:\n",
    "        pickle.dump(list_metrics,output)\n",
    "\n",
    "    with open(args.outdir_plots,'wb') as output:\n",
    "        pickle.dump(list_plots,output)\n",
    "\n",
    "    metrics = np.array(list_metrics)\n",
    "    metrics = metrics.transpose()\n",
    "\n",
    "    mean_nmse_net = np.round(np.mean(metrics[0]),2)\n",
    "    mean_nmse_interp = np.round(np.mean(metrics[1]),2)\n",
    "\n",
    "    mean_ncc_net = np.round(np.mean(metrics[2]),2)\n",
    "    mean_ncc_interp = np.round(np.mean(metrics[3]),2)\n",
    "\n",
    "    std_nmse_net = np.round(np.std(metrics[0]),2)\n",
    "    std_nmse_interp = np.round(np.std(metrics[1]),2)\n",
    "\n",
    "    std_ncc_net = np.round(np.std(metrics[2]),2)\n",
    "    std_ncc_interp = np.round(np.std(metrics[3]),2)\n",
    "\n",
    "    print('================== NMSE ==================')\n",
    "    print('U-net :  Mean = ' + str(mean_nmse_net)+' dB || Std = '+str(std_nmse_net)+' dB')\n",
    "    print('Interp : Mean = ' + str(mean_nmse_interp)+' dB || Std = '+str(std_nmse_interp)+' dB')\n",
    "    print('================== NCC ==================')\n",
    "    print('U-net :  Mean = ' + str(mean_ncc_net)+' | Std = '+str(std_ncc_net))\n",
    "    print('Interp : Mean = ' + str(mean_ncc_interp)+' || Std = '+str(std_ncc_interp))\n",
    "\n",
    "    reset_keras(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(probs[0]))\n",
    "# print(np.shape(ground_truth),\" \",np.shape(prediction),\" \",np.shape(interp_image))\n",
    "\n",
    "# # ground_truth_test = ground_truth[0][0]\n",
    "# # prediction_test = prediction[0][0]\n",
    "# ground_truth_test = ground_truth[:,:,0]\n",
    "# prediction_test = prediction[:,:,0]\n",
    "# interp_test = interp_image[:,:,0]\n",
    "\n",
    "# print(np.shape(ground_truth_test),\" \",np.shape(prediction_test),\" \",np.shape(interp_test))\n",
    "# print(ground_truth_test,\" \",prediction_test,\" \",interp_image)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
