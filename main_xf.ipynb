{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imort Part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAINING OF THE U-net FOR INPAINTING AND SUPER-RESOLUTION\n",
    "\n",
    "1) Train, validate and test the U-net on the available datasets:\n",
    "    - Dataset_xf\n",
    "    - Dataset_yf\n",
    "    - Dataset_xy\n",
    "   Each 2D image is normalised by the maximum before testing.\n",
    "\n",
    "2) The Dataset is divided as follows:\n",
    "    - 80% Train set\n",
    "    - 10% Validation set\n",
    "    - 10% Test set\n",
    "\n",
    "2) Both the weights of the trained network and the loss history are\n",
    "   saved with pickle, in order to both retrain the network using the wiìeight \n",
    "   of last training and to visualize losses\n",
    "\n",
    "2) Compute and save the costum metrics as: nmse, psnr\n",
    "   both for couples:\n",
    "   - (ground truth,learned image)\n",
    "   - (ground truth, interpolated image)\n",
    "   To compare performances of the U-net with respect to a classic interpolator\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.special import boxcox\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import keras as keras\n",
    "import keras.callbacks as cb\n",
    "from keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from Model_Unet import *\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from CustomMetricsLosses import *\n",
    "from scipy.interpolate import interp2d\n",
    "import argparse\n",
    "import os\n",
    "from random import sample\n",
    "from scipy.signal import resample\n",
    "\n",
    "# usa gpu con più memoria libera\n",
    "import GPUtil\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea sessione tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10498606797255667078\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7769907552\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9619734864627597742\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import clear_session\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=tf.compat.v1.ConfigProto()\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras(sess):\n",
    "\tclear_session()\n",
    "\tsess.close()\n",
    "\n",
    "def clip_normalize_power(in_content, mi, mx, p):\n",
    "    \"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for clipping\n",
    "    :param mx: max value for clipping\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized hard clipped image\n",
    "    \"\"\"\n",
    "    in_content = np.clip(in_content, a_min=mi, a_max=mx) #hard clip\n",
    "    in_content = 2 * (in_content - in_content.min()) / (in_content.max() - in_content.min()) - 1\n",
    "    in_content = np.power(np.abs(in_content), p)\n",
    "    return in_content\n",
    "\n",
    "def sigm_clip(in_content, mi, mx, p):\n",
    "    \"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for sigmoid function\n",
    "    :param mx: max value for sigmoid function\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized soft clipped image\n",
    "    \"\"\"\n",
    "    in_content =  mi + (mx-mi)*(lambda t: (1+300**(-t+0.5))**(-1) )( (in_content-mi)/(mx-mi) )  #sigmoid soft clip\n",
    "    in_content = 2 * (in_content - mi) / (mx - mi) - 1\n",
    "    in_content = np.power(np.abs(in_content), p)\n",
    "    return in_content\n",
    "\n",
    "def inv_sigm_clip(in_content, mi, mx, p):\n",
    "    \"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value used for inverting sigmoid\n",
    "    :param mx: max value used for inverting sigmoid\n",
    "    :param p: exponent for the power function (to be inverted)\n",
    "    :return: original image\n",
    "    \"\"\"\n",
    "    in_content = np.power(np.abs(in_content), 1/p)\n",
    "    #in_content = (in_content + 1) * (mx - mi) / 2 + mi\n",
    "    t = np.log((mx-mi)/(in_content-mi)-1)/np.log(300)\n",
    "    in_content = mi + (mx-mi)*(0.5-t)\n",
    "    return in_content\n",
    "\n",
    "def invertible_clipping(in_content, mi, mx, p):\n",
    "\t\"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for sigmoid function\n",
    "    :param mx: max value for sigmoid function\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized soft clipped image\n",
    "    \"\"\"\n",
    "\timage_clip = np.zeros(in_content.shape)\n",
    "    #Forward Clipping\n",
    "\ti,j = np.where(in_content < mi)\n",
    "\timage_clip[i, j] = 1e-4 * in_content[i, j] + (1 - 1e-4) * mi\n",
    "\ti,j = np.where(in_content > mx)\n",
    "\timage_clip[i, j] = 1e-4 * in_content[i, j] + (1 - 1e-4) * mx\n",
    "\ti,j = np.where((in_content >= mi) & (in_content <= mx))\n",
    "\timage_clip[i, j] = in_content[i, j]\n",
    "\n",
    "\t#Forward Normalization\n",
    "\t#real_mx = 1e-4 *1 + (1 - 1e-4) * mx\n",
    "\t#image_clip_norm = image_clip/real_mx\n",
    "\timage_clip_norm = 2 * (image_clip - mi) / (mx - mi) - 1\n",
    "\n",
    "\t#Forward Power\n",
    "\timage_clip_pow = np.power(np.abs(image_clip_norm), p)\n",
    "\treturn image_clip_pow\n",
    "\n",
    "def inv_invertible_clipping(in_content, mi, mx, p):\n",
    "\t#Backward Power\n",
    "\timage_inv_pow = np.power(np.abs(in_content), 1/p)\n",
    "\n",
    "\t#Backward Normalization\n",
    "\treal_mx = 1e-4 *1 + (1 - 1e-4) * mx\n",
    "\timage_inv_norm = image_inv_pow*real_mx\n",
    "\t#image_inv_norm = (image_inv_pow + 1) * (mx - mi) / 2 + mi\n",
    "\n",
    "\t#Backward Clipping\n",
    "\timage_inv = np.zeros(image_inv_norm.shape)\n",
    "\n",
    "\ti,j = np.where(image_inv_norm < mi)\n",
    "\timage_inv[i, j] = (image_inv_norm[i, j] - (1 - 1e-4) * mi) / 1e-4\n",
    "\ti,j = np.where(image_inv_norm > mx)\n",
    "\timage_inv[i, j] = (image_inv_norm[i, j] - (1 - 1e-4) * mx) / 1e-4\n",
    "\ti,j = np.where((image_inv_norm >= mi) & (image_inv_norm <= mx))\n",
    "\timage_inv[i, j] = image_inv_norm[i, j]\n",
    "\treturn image_inv\n",
    "\n",
    "def bc_clip(image, lam):\n",
    "    bc_image = boxcox(image, lam)\n",
    "    bc_min = bc_image.min()\n",
    "    bc_max = bc_image.max()\n",
    "    bc_image = (bc_image - bc_min) / (bc_max - bc_min)   \n",
    "    return (bc_image, bc_min, bc_max)\n",
    "\n",
    "def inv_bc_clip(image, mi, mx, lam):\n",
    "    bc_image = image * (mx - mi) + mi\n",
    "    bc_image = inv_boxcox(bc_image, lam)\n",
    "    return bc_image\n",
    "\n",
    "def normalize(in_content):\n",
    "\tin_content_abs = np.abs(in_content)\n",
    "\tin_content_norm = in_content_abs/in_content_abs.max()\n",
    "\treturn in_content_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Part(prepare&split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataset(imagetype,init,end,down_factor,snr_dB,downsampling,num_x_points,num_y_points,num_freqs):\n",
    "\n",
    "\tx = np.arange(0,num_x_points,1).tolist()\n",
    "\ty = np.arange(0,num_y_points,1).tolist()\n",
    "\n",
    "\timages = []\n",
    "\tzero_lines_idxs = []\n",
    "\tcounter_array = np.arange(init,end+1,1)\n",
    "\n",
    "\tdatapath = './dataset/DatasetFiles/Dataset_'+imagetype+'/Dataset_'+imagetype+'_'\n",
    "\n",
    "\tfor count in counter_array:\n",
    "\t\twith open(datapath+str(count), 'rb') as data:\n",
    "\t\t\tdati = pickle.load(data)\n",
    "\n",
    "\t\tperc=10\n",
    "\n",
    "\t\tprint('')\n",
    "\t\tprint('Preparing '+datapath+str(count))\n",
    "\t\tprint('')\n",
    "\n",
    "\t\tfor i in range(len(dati)):\n",
    "\t\t\tpercentage= round((i/len(dati))*100,0)\n",
    "\t\t\tif percentage==perc:\n",
    "\t\t\t\tprint('Percentage: '+str(perc)+'%')\n",
    "\t\t\t\tperc = perc+10\n",
    "\n",
    "\t\t\ttarget_img = np.array(dati[i][6])\n",
    "\t\t\tinput_img = np.array(dati[i][6])\n",
    "\n",
    "\t\t\t#addition of noise\n",
    "\t\t\tif snr_dB>0:\n",
    "\t\t\t\tif i==0:\n",
    "\t\t\t\t\tprint('')\n",
    "\t\t\t\t\tprint('Adding '+str(snr_dB)+' dB noise to input images')\n",
    "\t\t\t\t\tprint('')\n",
    "\t\t\t\tpower = np.mean(input_img ** 2)\n",
    "\t\t\t\tvar = power / (10 ** (snr_dB / 10))\n",
    "\t\t\t\tnoise = np.random.normal(0, np.sqrt(var), np.shape(input_img))\n",
    "\t\t\t\tinput_img = input_img+noise\n",
    "\n",
    "\t\t\tif datapath=='./dataset/DatasetFiles/Dataset_xy/Dataset_xy_':\n",
    "\t\t\t\tif downsampling=='random':\n",
    "\t\t\t\t\tif down_factor==2:\n",
    "\t\t\t\t\t\tx_sampled_list = sample(x,k=int(num_x_points*(1/down_factor)))\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif down_factor==4:\n",
    "\t\t\t\t\t\t\tx_sampled_list = sample(x,k=int(num_x_points*(2/down_factor)))\n",
    "\t\t\t\t\t\t\ty_sampled_list = sample(y,k=int(num_y_points*(2/down_factor)))\n",
    "\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tx_sampled_list = sample(x,k=int(num_x_points*(2/down_factor)))\n",
    "\t\t\t\t\t\t\ty_sampled_list = sample(y,k=int(num_y_points*(4/down_factor)))\n",
    "\n",
    "\t\t\t\t\t\ty_sampled_list.sort()\n",
    "\n",
    "\t\t\t\t\tx_sampled_list.sort()\n",
    "\n",
    "\t\t\t\t\tif down_factor==2:\n",
    "\t\t\t\t\t\tsampled_list = x_sampled_list\n",
    "\t\t\t\t\t\ti=0\n",
    "\t\t\t\t\t\tfor idx in x:\n",
    "\t\t\t\t\t\t\tif i==num_x_points*(1/down_factor):\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\telif idx!=sampled_list[i]:\n",
    "\t\t\t\t\t\t\t\tinput_img[:,idx]=np.zeros(num_y_points)\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\ti=i+1\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tsampled_list = x_sampled_list+y_sampled_list\n",
    "\t\t\t\t\t\tx_down_factor=down_factor/2\n",
    "\n",
    "\t\t\t\t\t\ti=0\n",
    "\n",
    "\t\t\t\t\t\tfor idx in x:\n",
    "\t\t\t\t\t\t\tif i==int(num_x_points*(1/x_down_factor)):\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\telif idx!=sampled_list[i]:\n",
    "\t\t\t\t\t\t\t\tinput_img[:,idx]=np.zeros(num_y_points)\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\ti=i+1\n",
    "\t\t\t\t\t\tfor idy in y:\n",
    "\t\t\t\t\t\t\tif i==len(sampled_list):\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\telif idy!=sampled_list[i]:\n",
    "\t\t\t\t\t\t\t\tinput_img[idy,:]=np.zeros(num_x_points)\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\ti=i+1\n",
    "\n",
    "\t\t\t\telif downsampling=='regular':\n",
    "\n",
    "\t\t\t\t\tif down_factor==2:\n",
    "\t\t\t\t\t\tsampled_list = x[::down_factor]\n",
    "\n",
    "\t\t\t\t\t\tfor idx in x:\n",
    "\t\t\t\t\t\t\tif idx%down_factor!=0:\n",
    "\t\t\t\t\t\t\t\tinput_img[:,idx]=np.zeros(num_y_points)\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tx_down_factor = int(down_factor/2)\n",
    "\t\t\t\t\t\tif down_factor==4:\n",
    "\t\t\t\t\t\t\ty_down_factor = x_down_factor\n",
    "\t\t\t\t\t\t\tsampled_list = x[::x_down_factor]+y[::y_down_factor]\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\ty_down_factor = int(x_down_factor/2)\n",
    "\t\t\t\t\t\t\tsampled_list = x[::x_down_factor]+y[::y_down_factor]\n",
    "\n",
    "\t\t\t\t\t\tfor idx in x:\n",
    "\t\t\t\t\t\t\tif idx%x_down_factor!=0:\n",
    "\t\t\t\t\t\t\t\tinput_img[:,idx]=np.zeros(num_y_points)\n",
    "\n",
    "\t\t\t\t\t\tfor idy in y:\n",
    "\t\t\t\t\t\t\tif idy%y_down_factor==0:\n",
    "\t\t\t\t\t\t\t\tinput_img[idy,:]=np.zeros(num_x_points)\n",
    "\t\t\t\t\n",
    "\t\t\t\t#print(sampled_list)\n",
    "\t\t\t\n",
    "\t\t\telif datapath=='./dataset/DatasetFiles/Dataset_yf/Dataset_yf_':\n",
    "\t\t\t\tif downsampling=='random':\n",
    "\t\t\t\t\tsampled_list = sample(y,k=int(num_y_points*(1-1/down_factor)))\n",
    "\t\t\t\t\tsampled_list.sort()\n",
    "\t\t\t\t\ti=0\n",
    "\t\t\t\t\tfor idx in y:\n",
    "\t\t\t\t\t\tif i==len(sampled_list):\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telif idx==sampled_list[i]:\n",
    "\t\t\t\t\t\t\tinput_img[idx,:]=np.zeros(num_freqs)\n",
    "\t\t\t\t\t\t\ti=i+1\n",
    "\t\t\t\telif downsampling=='regular':\n",
    "\t\t\t\t\tfor idy in y:\n",
    "\t\t\t\t\t\tif idy%down_factor!=0:\n",
    "\t\t\t\t\t\t\tinput_img[idy,:]=np.zeros(num_freqs)\n",
    "\n",
    "\t\t\telif datapath=='./dataset/DatasetFiles/Dataset_xf/Dataset_xf_':\n",
    "\n",
    "\t\t\t\tif num_x_points<64: #it means the image is real\n",
    "\t\t\t\t\ttarget_img = np.array(dati[i][6][16:16+32,:])\n",
    "\t\t\t\t\tinput_img = np.array(dati[i][6][16:16+32,:])\n",
    "\n",
    "\t\t\t\tif downsampling=='random':\n",
    "\t\t\t\t\tsampled_list = sample(x,k=int(num_x_points*(1/down_factor)))\n",
    "\t\t\t\t\tsampled_list.sort()\n",
    "\n",
    "\t\t\t\t\ti=0\n",
    "\t\t\t\t\tfor idx in x:\n",
    "\t\t\t\t\t\tif i==num_x_points*(1/down_factor):\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telif idx!=sampled_list[i]:\n",
    "\t\t\t\t\t\t\tinput_img[idx,:]=np.zeros(num_freqs)\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\ti=i+1\n",
    "\n",
    "\t\t\t\telif downsampling=='regular':\n",
    "\t\t\t\t\tsampled_list = x[::down_factor]\n",
    "\n",
    "\t\t\t\t\tfor idx in x:\n",
    "\t\t\t\t\t\tif idx%down_factor!=0:\n",
    "\t\t\t\t\t\t\tinput_img[idx,:]=np.zeros(num_freqs)\n",
    "\t\t\t\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\t\t\tif imagetype!='xy' and np.mean(target_img**2)>1e-10:\n",
    "\t\t\t\timages.append((input_img,target_img))\n",
    "\t\t\t\tzero_lines_idxs.append(sampled_list)\n",
    "\n",
    "\t\t\t\t'''plt.subplot(121), plt.title('Input xy image')\n",
    "\t\t\t\tplt.imshow(input_img, cmap='bone', aspect='auto'), plt.colorbar()\n",
    "\t\t\t\tplt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "\t\t\t\tplt.grid(None)\n",
    "\t\t\t\tplt.subplot(122), plt.title('Target xy image')\n",
    "\t\t\t\tplt.imshow(target_img, cmap='bone', aspect='auto'), plt.colorbar()\n",
    "\t\t\t\tplt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "\t\t\t\tplt.grid(None)\n",
    "\t\t\t\tplt.show()'''\n",
    "\n",
    "\t### ADD CHANNEL DIMENSION\n",
    "\n",
    "\tprint('')\n",
    "\tprint('Dataset ready to be splitted --> '+str(len(images))+' images')\n",
    "\tprint('')\n",
    "\n",
    "\timages = np.array(images)\n",
    "\tif datapath=='./dataset/DatasetFiles/Dataset_xf/Dataset_xf_':\n",
    "\t\timages = images.reshape(len(images),2,num_x_points,num_freqs,1)\n",
    "\telif datapath=='./dataset/DatasetFiles/Dataset_yf/Dataset_yf_':\n",
    "\t\timages = images.reshape(len(images),2,num_y_points,num_freqs,1)\n",
    "\telif datapath=='./dataset/DatasetFiles/Dataset_xy/Dataset_xy_':\n",
    "\t\timages = images.reshape(len(images),2,num_y_points,num_x_points,1)\n",
    "\n",
    "\treturn images, zero_lines_idxs\n",
    "\n",
    "def splitDataset(dataset,zero_lines_idxs,batch_size,lam):\n",
    "\t### DIVIDING THE DATASET INTO TRAIN, VALIDATION AND TEST SETS\n",
    "\tshuffler = np.random.permutation(len(dataset))\n",
    "\n",
    "\tdataset = np.array(dataset, dtype='float32')\n",
    "\tzero_lines_idxs = np.array(zero_lines_idxs)\n",
    "\n",
    "\tdataset = dataset[shuffler]\n",
    "\tzero_lines_idxs = zero_lines_idxs[shuffler]\n",
    "\n",
    "\ttrain, val, test = np.split(dataset,[int(.8 * len(dataset)),int(.9 * len(dataset))])\n",
    "\ttrain_zli, val_zli, test_zli = np.split(zero_lines_idxs,[int(.8 * len(zero_lines_idxs)),int(.9 * len(zero_lines_idxs))])\n",
    "\n",
    "\tX_train = []\n",
    "\tY_train = []\n",
    "\n",
    "\tprint(\"Preparing training set \")\n",
    "\ttrain_samples = len(train)-len(train)%batch_size\n",
    "\tfor idx in range(train_samples):\n",
    "\t\t'''input_img_eq, mini, maxi = bc_clip(train[idx][0],lam)\n",
    "\t\ttarget_img_eq, mint, maxt = bc_clip(train[idx][1],lam)'''\n",
    "\t\tX_train.append(normalize(train[idx][0]))\n",
    "\t\tY_train.append(normalize(train[idx][1]))\n",
    "\t\t'''X_train.append(input_img_eq)\n",
    "\t\tY_train.append(target_img_eq)'''\n",
    "\n",
    "\tX_train = np.array(X_train)\n",
    "\tY_train = np.array(Y_train)\n",
    "\n",
    "\tprint(\"Training sets ready :\"+str(np.shape(X_train)))\n",
    "\tprint('')\n",
    "\n",
    "\tX_val = []\n",
    "\tY_val = []\n",
    "\n",
    "\tprint(\"Preparing validation set \")\n",
    "\tval_samples = len(val)-len(val)%batch_size\n",
    "\tfor idx in range(val_samples):\n",
    "\t\t'''input_img_eq, mini, maxi = bc_clip(val[idx][0],lam)\n",
    "\t\ttarget_img_eq, mint, maxt = bc_clip(val[idx][1],lam)'''\n",
    "\t\tX_val.append(normalize(val[idx][0]))\n",
    "\t\tY_val.append(normalize(val[idx][1]))\n",
    "\t\t'''X_val.append(input_img_eq)\n",
    "\t\tY_val.append(target_img_eq)'''\n",
    "\n",
    "\tX_val = np.array(X_val)\n",
    "\tY_val = np.array(Y_val)\n",
    "\n",
    "\tprint(\"Validation set ready :\"+str(np.shape(X_val)))\n",
    "\tprint('')\n",
    "\n",
    "\tX_test = []\n",
    "\tY_test = []\n",
    "\tX_test_noeq = []\n",
    "\tY_test_noeq = []\n",
    "\tdynamics = []\n",
    "\n",
    "\tprint(\"Preparing test set \")\n",
    "\ttest_samples = len(test)-len(test)%batch_size\n",
    "\tfor idx in range(test_samples):\n",
    "\t\t'''input_img_eq, mini, maxi = bc_clip(test[idx][0],lam)\n",
    "\t\ttarget_img_eq, mint, maxt = bc_clip(test[idx][1],lam)'''\n",
    "\t\tX_test.append(normalize(test[idx][0]))\n",
    "\t\tY_test.append(normalize(test[idx][1]))\n",
    "\t\t'''X_test_noeq.append(test[idx][0])\n",
    "\t\tY_test_noeq.append(test[idx][1])\n",
    "\t\t#dynamics.append((maxt,mint))'''\n",
    "\n",
    "\tX_test = np.array(X_test)\n",
    "\tY_test = np.array(Y_test)\n",
    "\t'''X_test_noeq = np.array(X_test_noeq)\n",
    "\tY_test_noeq = np.array(Y_test_noeq)\n",
    "\tdynamics = np.array(dynamics)'''\n",
    "\n",
    "\tprint(\"Test set ready :\"+str(np.shape(X_test)))\n",
    "\tprint('')\n",
    "\n",
    "\t#return X_train,Y_train,X_val,Y_val,X_test,Y_test,X_test_noeq,Y_test_noeq,dynamics\n",
    "\treturn X_train,Y_train,X_val,Y_val,X_test,Y_test,test_zli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial part (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing ./dataset/DatasetFiles/Dataset_xf/Dataset_xf_1\n",
      "\n",
      "Percentage: 10%\n",
      "Percentage: 20%\n",
      "Percentage: 30%\n",
      "Percentage: 40%\n",
      "Percentage: 50%\n",
      "Percentage: 60%\n",
      "Percentage: 70%\n",
      "Percentage: 80%\n",
      "Percentage: 90%\n",
      "Percentage: 100%\n",
      "\n",
      "Dataset ready to be splitted --> 2352 images\n",
      "\n",
      "Preparing training set \n",
      "Training sets ready :(1881, 64, 1024, 1)\n",
      "\n",
      "Preparing validation set \n",
      "Validation set ready :(235, 64, 1024, 1)\n",
      "\n",
      "Preparing test set \n",
      "Test set ready :(236, 64, 1024, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    args = easydict.EasyDict({\n",
    "        \"imagetype\": 'xf',\n",
    "        \"outdir\": './ModelCheckpoint/super_res_xf.h5',\n",
    "        \"outdir_trainhistory\": './ModelCheckpoint/th_xf',\n",
    "        \"outdir_metrics\": './Metrics/Metrics_behaviour_xf',\n",
    "        \"outdir_plots\": './Plots/Plot_xf',\n",
    "        \"lam\": 0.3,\n",
    "        \"down_factor\": 4,\n",
    "        \"downsampling\": 'regular',\n",
    "        \"lr\": 0.0004,\n",
    "        \"num_freqs\": 1024,\n",
    "        \"snr\": 0,\n",
    "        \"batch_size\": 1,\n",
    "        \"num_x_points\": 64,\n",
    "        \"num_y_points\": 16,\n",
    "        \"epochs\": 1,\n",
    "        \"train_session\": 1,      # 1 2 3\n",
    "        \"init_dataset_idx\": 1,   # 1 5 8\n",
    "        \"final_dataset_idx\": 1   # 4 7 10\n",
    "})\n",
    "    #inizializza variabili globali\n",
    "    num_x_points = args.num_x_points\n",
    "    num_y_points = args.num_y_points\n",
    "    num_freqs = args.num_freqs\n",
    "    x = np.arange(0,num_x_points,1).tolist() # x-axis\n",
    "    y = np.arange(0,num_y_points,1).tolist() # y-axis\n",
    "    freq = np.arange(0,num_freqs,1).tolist()  #frequency axis\n",
    "\n",
    "    dataset,zero_lines_idxs = prepareDataset(args.imagetype,args.init_dataset_idx,args.final_dataset_idx,args.down_factor,args.snr,args.downsampling, \n",
    "        num_x_points, num_y_points, num_freqs)\n",
    "\n",
    "    X_train,Y_train,X_val,Y_val,X_test,Y_test,test_zli = splitDataset(dataset,zero_lines_idxs,args.batch_size,args.lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import sys\n",
    "# print(\"=====================Dataset=====================\")\n",
    "# print(\"size of the X_train: \",sys.getsizeof(X_train),\"bytes\")\n",
    "# # print(\"shape of the X_train: \",[len(a) for a in X_train])\n",
    "# print(\"type of the X_train: \",type(X_train))\n",
    "# print(\"shape of the X_train: \",np.shape(X_train))\n",
    "# print(\"shape of the Y_train: \",np.shape(Y_train))\n",
    "\n",
    "# print(\"\\nshape of the X_val: \",np.shape(X_val))\n",
    "# print(\"shape of the Y_val: \",np.shape(Y_val))\n",
    "\n",
    "# print(\"\\nshape of the X_test: \",np.shape(X_test))\n",
    "# print(\"shape of the Y_test: \",np.shape(Y_test))\n",
    "\n",
    "# print(\"\\nshape of the dataset: \",np.shape(dataset))\n",
    "# print(\"shape of the zero_lines_idxs: \",np.shape(zero_lines_idxs))\n",
    "# print(\"shape of the test_zli: \",np.shape(test_zli))\n",
    "# # print(\"test_zli: \",test_zli)\n",
    "# print(\"num_x_points:\",num_x_points)\n",
    "# print(\"num_y_points:\",num_y_points)\n",
    "# print(\"num_freqs:\",num_freqs)\n",
    "# print(\"================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compile model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model\n",
      "\n",
      "=====================first_dim: 64 =====================second_dim: 1024\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 1024, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d (Reflectio (None, 66, 1026, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 1024, 16) 160         reflection_padding2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 1024, 16) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_1 (Reflect (None, 66, 1026, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 1024, 16) 2320        reflection_padding2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 1024, 16) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 512, 16)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_2 (Reflect (None, 34, 514, 16)  0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 512, 32)  4640        reflection_padding2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 512, 32)  128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_3 (Reflect (None, 34, 514, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 512, 32)  9248        reflection_padding2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 512, 32)  128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 256, 32)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_4 (Reflect (None, 18, 258, 32)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 256, 64)  18496       reflection_padding2d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 256, 64)  64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_5 (Reflect (None, 18, 258, 64)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 256, 64)  36928       reflection_padding2d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 256, 64)  64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 128, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_6 (Reflect (None, 10, 130, 64)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 128, 128)  73856       reflection_padding2d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 128, 128)  32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_7 (Reflect (None, 10, 130, 128) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 128, 128)  147584      reflection_padding2d_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 128, 128)  32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 64, 128)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 64, 256)   295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 64, 256)   16          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 64, 256)   590080      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 64, 256)   16          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 128, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 128, 384)  0           up_sampling2d[0][0]              \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_8 (Reflect (None, 10, 130, 384) 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 128, 128)  442496      reflection_padding2d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 128, 128)  32          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_9 (Reflect (None, 10, 130, 128) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 128, 128)  147584      reflection_padding2d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 128, 128)  32          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 256, 128) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 256, 192) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_10 (Reflec (None, 18, 258, 192) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 256, 64)  110656      reflection_padding2d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 256, 64)  64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_11 (Reflec (None, 18, 258, 64)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 256, 64)  36928       reflection_padding2d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 256, 64)  64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 512, 64)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 512, 96)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_12 (Reflec (None, 34, 514, 96)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 512, 32)  27680       reflection_padding2d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 512, 32)  128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_13 (Reflec (None, 34, 514, 32)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 512, 32)  9248        reflection_padding2d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 512, 32)  128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 1024, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 1024, 48) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_14 (Reflec (None, 66, 1026, 48) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 1024, 16) 6928        reflection_padding2d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 1024, 16) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_15 (Reflec (None, 66, 1026, 16) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 1024, 16) 2320        reflection_padding2d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 1024, 16) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 1024, 1)  17          batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,964,289\n",
      "Trainable params: 1,963,313\n",
      "Non-trainable params: 976\n",
      "__________________________________________________________________________________________________\n",
      "Model compiled. Training model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"Compiling model\")\n",
    "    print('')\n",
    "    # Build&Compile Neural Networks\n",
    "    if args.imagetype=='xf':\n",
    "        uNet = uNet1(num_x_points,num_freqs)\n",
    "    elif args.imagetype=='yf':\n",
    "        uNet = uNet1(num_y_points,num_freqs)\n",
    "    else:\n",
    "        uNet = uNet1(num_y_points,num_x_points)\n",
    "\n",
    "    uNet.summary()\n",
    "\n",
    "    if args.train_session>1:\n",
    "        print('Loading weights')\n",
    "        uNet.load_weights(args.outdir)\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "    if args.imagetype=='xy':\n",
    "        uNet.compile(loss=mse, optimizer=opt, metrics=[NMSE, ncc])\n",
    "    elif args.imagetype=='xf':\n",
    "        uNet.compile(loss=mask_mse(args.batch_size,args.num_x_points), optimizer=opt, metrics=[NMSE, ncc])\n",
    "    elif args.imagetype=='yf':\n",
    "        uNet.compile(loss=mask_mse(args.batch_size,args.num_y_points), optimizer=opt, metrics=[NMSE, ncc])\n",
    "\n",
    "    callback = [#EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.2),\n",
    "                ModelCheckpoint(\n",
    "                    filepath=args.outdir,\n",
    "                    monitor='val_loss', verbose=1, save_best_only=True)]\n",
    "\n",
    "    print(\"Model compiled. Training model\")\n",
    "    print('')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the U-net model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mask_mse.<locals>.loss at 0x7fcc2c2a64c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function mask_mse.<locals>.loss at 0x7fcc2c2a64c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1881/1881 [==============================] - 77s 20ms/step - loss: 3.3115e-04 - NMSE: -16.2340 - ncc: 0.8963 - val_loss: 2.4434e-06 - val_NMSE: -33.5358 - val_ncc: 0.9885\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00000, saving model to ./ModelCheckpoint/super_res_xf.h5\n",
      "{'name': 'reflection_padding2d', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_1', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_2', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_3', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_4', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_5', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_6', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_7', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_8', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_9', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_10', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_11', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_12', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_13', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_14', 'trainable': True, 'dtype': 'float32'}\n",
      "{'name': 'reflection_padding2d_15', 'trainable': True, 'dtype': 'float32'}\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\t### TRAINING THE U-net\n",
    "\n",
    "\thistory = uNet.fit(X_train, Y_train, epochs=args.epochs, verbose=1, callbacks=callback, validation_data=(X_val, Y_val),batch_size=args.batch_size)\n",
    "\n",
    "\twith open(args.outdir_trainhistory, 'wb') as file_pi:\n",
    "\t\tpickle.dump(history.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 2.4269e-06 - NMSE: -33.0443 - ncc: 0.9877\n",
      "236/236 [==============================] - 2s 7ms/step\n",
      "score: [2.4269074856420048e-06, -33.044334411621094, 0.9877383708953857]\n",
      "\n",
      "Custom metrics and plot results\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\t### TESTING THE U-net\n",
    "\n",
    "\tprint('')\n",
    "\tprint(\"Testing\")\n",
    "\tscore = uNet.evaluate(X_test, Y_test, verbose=1, batch_size=args.batch_size)\n",
    "\tprobs = uNet.predict(X_test, verbose=1, batch_size=args.batch_size)\n",
    "\tprint(\"score:\",score)\n",
    "\tprint('')\n",
    "\tprint(\"Custom metrics and plot results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate custom matrics and save them using pickle (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== NMSE ==================\n",
      "U-net :  Mean = -33.04 dB || Std = 4.27 dB\n",
      "Interp : Mean = -68.5 dB || Std = 7.61 dB\n",
      "================== NCC ==================\n",
      "U-net :  Mean = 0.99 | Std = 0.01\n",
      "Interp : Mean = 1.0 || Std = 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\t### CALCULATE THE CUSTOM METRICS AND SAVE THEM USING PICKLE\n",
    "\n",
    "\tif args.imagetype=='xy':\n",
    "\t\tif args.down_factor==2:\n",
    "\t\t\tx_ds = np.arange(0,num_x_points,args.down_factor) # down-sampled x-axis vector\n",
    "\t\t\ty_ds = y\n",
    "\t\telif args.down_factor==4:\n",
    "\t\t\tx_ds = np.arange(0,num_x_points,int(args.down_factor/2)) \n",
    "\t\t\ty_ds = np.arange(0,num_y_points,int(args.down_factor/2))\n",
    "\t\telse:\n",
    "\t\t\tx_ds = np.arange(0,num_x_points,int(args.down_factor/2)) \n",
    "\t\t\ty_ds = np.arange(0,num_y_points,int(args.down_factor/4))\n",
    "\telse:\n",
    "\t\tx_ds = np.arange(0,num_x_points,args.down_factor)\n",
    "\t\ty_ds = np.arange(0,num_y_points,args.down_factor)\n",
    "\n",
    "\tlist_metrics = []\n",
    "\tlist_plots = []\n",
    "\n",
    "\tfor idx in range(len(Y_test)):\n",
    "\t\tdown = X_test[idx][:,:,0]\n",
    "\t\tground_truth = Y_test[idx][:,:,0]\n",
    "\t\tprediction = probs[idx][:,:,0]\n",
    "\n",
    "\t\tnmse1 = nmse(ground_truth,prediction)\n",
    "\t\tncc1 = NCC(ground_truth,prediction)\n",
    "\n",
    "\t\tzero_row_idxs = test_zli[idx]\n",
    "\n",
    "\t\tif args.imagetype=='xy':\n",
    "\t\t\tif args.downsampling=='random':\n",
    "\n",
    "\t\t\t\tif args.down_factor==2:\n",
    "\t\t\t\t\tds_image = np.zeros((num_y_points,int(num_x_points/args.down_factor)))\n",
    "\n",
    "\t\t\t\t\tzero_row_idx=0\n",
    "\t\t\t\t\tcount=0\n",
    "\n",
    "\t\t\t\t\tfor j in x:\n",
    "\t\t\t\t\t\tif j==zero_row_idxs[zero_row_idx]:\n",
    "\t\t\t\t\t\t\tds_image[:,count] = down[:,j]\n",
    "\t\t\t\t\t\t\tcount=count+1\n",
    "\t\t\t\t\t\t\tzero_row_idx=zero_row_idx+1\n",
    "\t\t\t\t\t\tif zero_row_idx==num_x_points*(1/args.down_factor):\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tx_ds_image = np.zeros((num_y_points,2*int(num_x_points/args.down_factor)))\n",
    "\n",
    "\t\t\t\t\tzero_row_idx=0\n",
    "\t\t\t\t\tcount=0\n",
    "\n",
    "\t\t\t\t\tfor j in x:\n",
    "\t\t\t\t\t\tif j==zero_row_idxs[zero_row_idx]:\n",
    "\t\t\t\t\t\t\tx_ds_image[:,count] = down[:,j]\n",
    "\t\t\t\t\t\t\tcount=count+1\n",
    "\t\t\t\t\t\t\tzero_row_idx=zero_row_idx+1\n",
    "\t\t\t\t\t\tif zero_row_idx==num_x_points*(2/args.down_factor):\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\t\tcount=0\n",
    "\n",
    "\t\t\t\t\tif args.down_factor==4:\n",
    "\t\t\t\t\t\tds_image = np.zeros((2*int(num_y_points/args.down_factor),2*int(num_x_points/args.down_factor)))\n",
    "\n",
    "\t\t\t\t\telif args.down_factor==8:\n",
    "\t\t\t\t\t\tds_image = np.zeros((4*int(num_y_points/args.down_factor),2*int(num_x_points/args.down_factor)))\n",
    "\n",
    "\t\t\t\t\tfor i in y:\n",
    "\t\t\t\t\t\tif i==zero_row_idxs[zero_row_idx]:\n",
    "\t\t\t\t\t\t\tds_image[count,:] = x_ds_image[i,:]\n",
    "\t\t\t\t\t\t\tcount=count+1\n",
    "\t\t\t\t\t\t\tzero_row_idx=zero_row_idx+1\n",
    "\t\t\t\t\t\tif zero_row_idx==len(zero_row_idxs):\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\telif args.downsampling=='regular':\n",
    "\t\t\t\tif args.down_factor==8:\n",
    "\t\t\t\t\tds_image = ground_truth[::int(args.down_factor/4),::int(args.down_factor/2)]\n",
    "\t\t\t\telif args.down_factor==4:\n",
    "\t\t\t\t\tds_image = ground_truth[::int(args.down_factor/2),::int(args.down_factor/2)]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tds_image = ground_truth[:,::args.down_factor]\n",
    "\n",
    "\t\t\t'''interp = interp2d(x_ds, y_ds, ds_image, kind='cubic')\n",
    "\t\t\tinterp_image = interp(x,y)'''\n",
    "\t\t\tinterp_y = resample(ds_image,num_y_points,axis=0)\n",
    "\t\t\tinterp_image = resample(interp_y,num_x_points,axis=1)\n",
    "\n",
    "\t\telif args.imagetype=='xf':\n",
    "\n",
    "\t\t\tif args.downsampling=='random':\n",
    "\n",
    "\t\t\t\tds_image = np.zeros((int(num_x_points/args.down_factor),num_freqs))\n",
    "\n",
    "\t\t\t\tzero_row_idx=0\n",
    "\t\t\t\tcount=0\n",
    "\n",
    "\t\t\t\tfor j in x:\n",
    "\t\t\t\t\tif j==zero_row_idxs[zero_row_idx]:\n",
    "\t\t\t\t\t\tds_image[count,:] = down[j,:]\n",
    "\t\t\t\t\t\tcount=count+1\n",
    "\t\t\t\t\t\tzero_row_idx=zero_row_idx+1\n",
    "\t\t\t\t\tif zero_row_idx==num_x_points*(1/args.down_factor):\n",
    "\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\telif args.downsampling=='regular':\n",
    "\t\t\t\t\tds_image = ground_truth[::args.down_factor,:]\n",
    "\n",
    "\t\t\t'''interp = interp2d(freq, x_ds, ds_image, kind='cubic')\n",
    "\t\t\tinterp_image = interp(freq,x)'''\n",
    "\t\t\tinterp_image = resample(ds_image,num_x_points,axis=0)\n",
    "\n",
    "# \t\t\tplt.subplot(141), plt.title('Target')\n",
    "# \t\t\tplt.imshow(np.clip(ground_truth, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# \t\t\tplt.xlabel('Freq [Hz]'), plt.ylabel('X [m]')\n",
    "# \t\t\tplt.grid(None)\n",
    "# \t\t\tplt.subplot(142), plt.title('U-net input')\n",
    "# \t\t\tplt.imshow(np.clip(down, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# \t\t\tplt.xlabel('Freq [Hz]')\n",
    "# \t\t\tplt.grid(None)\n",
    "# \t\t\tplt.subplot(143), plt.title('Interp input')\n",
    "# \t\t\tplt.imshow(np.clip(ds_image, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# \t\t\tplt.xlabel('Freq [Hz]')\n",
    "# \t\t\tplt.grid(None)\n",
    "# \t\t\tplt.subplot(144), plt.title('Interp output')\n",
    "# \t\t\tplt.imshow(np.clip(interp_image, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# \t\t\tplt.xlabel('Freq [Hz]')\n",
    "# \t\t\tplt.grid(None)\n",
    "# \t\t\tplt.show()\n",
    "\n",
    "\t\telif args.imagetype=='yf':\n",
    "\t\t\tif args.downsampling=='random':\n",
    "\t\t\t\tds_image=down[~np.all(down==0, axis=1)]\n",
    "\n",
    "\t\t\t\tif len(ds_image)==num_y_points/args.down_factor-2:\n",
    "\t\t\t\t\tds_image = np.concatenate((np.zeros((1,num_freqs)),ds_image), 0)\n",
    "\t\t\t\t\tds_image = np.concatenate((ds_image,np.zeros((1,num_freqs))), 0)\n",
    "\n",
    "\t\t\t\telif len(ds_image)==num_y_points/args.down_factor-1:\n",
    "\t\t\t\t\tif np.max(ground_truth[0,:])==0:\n",
    "\t\t\t\t\t\tds_image = np.concatenate((np.zeros((1,num_freqs)),ds_image), 0)\n",
    "\n",
    "\t\t\t\t\telif np.max(ground_truth[num_y_points-1,:])==0:\n",
    "\t\t\t\t\t\tds_image = np.concatenate((ds_image,np.zeros((1,num_freqs))), 0)\n",
    "\n",
    "\t\t\telif args.downsampling=='regular':\n",
    "\t\t\t\tds_image = ground_truth[::args.down_factor,:]\n",
    "\n",
    "\t\t\t'''interp = interp2d(freq, y_ds, ds_image, kind='cubic')\n",
    "\t\t\tinterp_image = interp(freq,y)'''\n",
    "\t\t\tinterp_image = resample(ds_image,num_y_points,axis=0)\n",
    "\n",
    "\t\tnmse2 = nmse(ground_truth,interp_image)\n",
    "\t\tncc2 = NCC(ground_truth,interp_image)\n",
    "\n",
    "\t\tif args.snr>0:\n",
    "\t\t\tlist_metrics.append((nmse1,ncc1))\n",
    "\t\t\tlist_plots.append((down,ground_truth,prediction))\n",
    "\t\telse:\n",
    "\t\t\tlist_metrics.append((nmse1,nmse2,ncc1,ncc2))\n",
    "\t\t\tif idx<50:\n",
    "\t\t\t\tlist_plots.append((down,ground_truth,prediction,interp_image))\n",
    "\n",
    "\twith open(args.outdir_metrics,'wb') as output:\n",
    "\t\tpickle.dump(list_metrics,output)\n",
    "\n",
    "\twith open(args.outdir_plots,'wb') as output:\n",
    "\t\tpickle.dump(list_plots,output)\n",
    "\n",
    "\tmetrics = np.array(list_metrics)\n",
    "\tmetrics = metrics.transpose()\n",
    "\n",
    "\tmean_nmse_net = round(np.mean(metrics[0]),2)\n",
    "\tmean_nmse_interp = round(np.mean(metrics[1]),2)\n",
    "\n",
    "\tmean_ncc_net = round(np.mean(metrics[2]),2)\n",
    "\tmean_ncc_interp = round(np.mean(metrics[3]),2)\n",
    "\n",
    "\tstd_nmse_net = round(np.std(metrics[0]),2)\n",
    "\tstd_nmse_interp = round(np.std(metrics[1]),2)\n",
    "\n",
    "\tstd_ncc_net = round(np.std(metrics[2]),2)\n",
    "\tstd_ncc_interp = round(np.std(metrics[3]),2)\n",
    "\n",
    "\tprint('================== NMSE ==================')\n",
    "\tprint('U-net :  Mean = ' + str(mean_nmse_net)+' dB || Std = '+str(std_nmse_net)+' dB')\n",
    "\tprint('Interp : Mean = ' + str(mean_nmse_interp)+' dB || Std = '+str(std_nmse_interp)+' dB')\n",
    "\tprint('================== NCC ==================')\n",
    "\tprint('U-net :  Mean = ' + str(mean_ncc_net)+' | Std = '+str(std_ncc_net))\n",
    "\tprint('Interp : Mean = ' + str(mean_ncc_interp)+' || Std = '+str(std_ncc_interp))\n",
    "\n",
    "\treset_keras(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
