{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imort Part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAINING OF THE U-net FOR INPAINTING AND SUPER-RESOLUTION\n",
    "\n",
    "1) Train, validate and test the U-net on the available datasets:\n",
    "    - Dataset_xf\n",
    "    - Dataset_yf\n",
    "    - Dataset_xy\n",
    "   Each 2D image is normalised by the maximum before testing.\n",
    "\n",
    "2) The Dataset is divided as follows:\n",
    "    - 80% Train set\n",
    "    - 10% Validation set\n",
    "    - 10% Test set\n",
    "\n",
    "2) Both the weights of the trained network and the loss history are\n",
    "   saved with pickle, in order to both retrain the network using the wiìeight \n",
    "   of last training and to visualize losses\n",
    "\n",
    "2) Compute and save the costum metrics as: nmse, psnr\n",
    "   both for couples:\n",
    "   - (ground truth,learned image)\n",
    "   - (ground truth, interpolated image)\n",
    "   To compare performances of the U-net with respect to a classic interpolator\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.special import boxcox\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import keras as keras\n",
    "import keras.callbacks as cb\n",
    "from keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from Model_Unet_complex import *\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from CustomMetricsLosses import *\n",
    "from scipy.interpolate import interp2d\n",
    "import argparse\n",
    "import os\n",
    "from random import sample\n",
    "from scipy.signal import resample\n",
    "\n",
    "# usa gpu con più memoria libera\n",
    "import GPUtil\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea sessione tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3854324577203318581\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7769907552\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18446694796218544693\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import clear_session\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=tf.compat.v1.ConfigProto()\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras(sess):\n",
    "\tclear_session()\n",
    "\tsess.close()\n",
    "\n",
    "def clip_normalize_power(in_content, mi, mx, p):\n",
    "    \"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for clipping\n",
    "    :param mx: max value for clipping\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized hard clipped image\n",
    "    \"\"\"\n",
    "    in_content = np.clip(in_content, a_min=mi, a_max=mx) #hard clip\n",
    "    in_content = 2 * (in_content - in_content.min()) / (in_content.max() - in_content.min()) - 1\n",
    "    in_content = np.power(np.abs(in_content), p)\n",
    "    return in_content\n",
    "\n",
    "def sigm_clip(in_content, mi, mx, p):\n",
    "    \"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for sigmoid function\n",
    "    :param mx: max value for sigmoid function\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized soft clipped image\n",
    "    \"\"\"\n",
    "    in_content =  mi + (mx-mi)*(lambda t: (1+300**(-t+0.5))**(-1) )( (in_content-mi)/(mx-mi) )  #sigmoid soft clip\n",
    "    in_content = 2 * (in_content - mi) / (mx - mi) - 1\n",
    "    in_content = np.power(np.abs(in_content), p)\n",
    "    return in_content\n",
    "\n",
    "def inv_sigm_clip(in_content, mi, mx, p):\n",
    "    \"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value used for inverting sigmoid\n",
    "    :param mx: max value used for inverting sigmoid\n",
    "    :param p: exponent for the power function (to be inverted)\n",
    "    :return: original image\n",
    "    \"\"\"\n",
    "    in_content = np.power(np.abs(in_content), 1/p)\n",
    "    #in_content = (in_content + 1) * (mx - mi) / 2 + mi\n",
    "    t = np.log((mx-mi)/(in_content-mi)-1)/np.log(300)\n",
    "    in_content = mi + (mx-mi)*(0.5-t)\n",
    "    return in_content\n",
    "\n",
    "def invertible_clipping(in_content, mi, mx, p):\n",
    "\t\"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for sigmoid function\n",
    "    :param mx: max value for sigmoid function\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized soft clipped image\n",
    "    \"\"\"\n",
    "\timage_clip = np.zeros(in_content.shape)\n",
    "    #Forward Clipping\n",
    "\ti,j = np.where(in_content < mi)\n",
    "\timage_clip[i, j] = 1e-4 * in_content[i, j] + (1 - 1e-4) * mi\n",
    "\ti,j = np.where(in_content > mx)\n",
    "\timage_clip[i, j] = 1e-4 * in_content[i, j] + (1 - 1e-4) * mx\n",
    "\ti,j = np.where((in_content >= mi) & (in_content <= mx))\n",
    "\timage_clip[i, j] = in_content[i, j]\n",
    "\n",
    "\t#Forward Normalization\n",
    "\t#real_mx = 1e-4 *1 + (1 - 1e-4) * mx\n",
    "\t#image_clip_norm = image_clip/real_mx\n",
    "\timage_clip_norm = 2 * (image_clip - mi) / (mx - mi) - 1\n",
    "\n",
    "\t#Forward Power\n",
    "\timage_clip_pow = np.power(np.abs(image_clip_norm), p)\n",
    "\treturn image_clip_pow\n",
    "\n",
    "def inv_invertible_clipping(in_content, mi, mx, p):\n",
    "\t#Backward Power\n",
    "\timage_inv_pow = np.power(np.abs(in_content), 1/p)\n",
    "\n",
    "\t#Backward Normalization\n",
    "\treal_mx = 1e-4 *1 + (1 - 1e-4) * mx\n",
    "\timage_inv_norm = image_inv_pow*real_mx\n",
    "\t#image_inv_norm = (image_inv_pow + 1) * (mx - mi) / 2 + mi\n",
    "\n",
    "\t#Backward Clipping\n",
    "\timage_inv = np.zeros(image_inv_norm.shape)\n",
    "\n",
    "\ti,j = np.where(image_inv_norm < mi)\n",
    "\timage_inv[i, j] = (image_inv_norm[i, j] - (1 - 1e-4) * mi) / 1e-4\n",
    "\ti,j = np.where(image_inv_norm > mx)\n",
    "\timage_inv[i, j] = (image_inv_norm[i, j] - (1 - 1e-4) * mx) / 1e-4\n",
    "\ti,j = np.where((image_inv_norm >= mi) & (image_inv_norm <= mx))\n",
    "\timage_inv[i, j] = image_inv_norm[i, j]\n",
    "\treturn image_inv\n",
    "\n",
    "def bc_clip(image, lam):\n",
    "    bc_image = boxcox(image, lam)\n",
    "    bc_min = bc_image.min()\n",
    "    bc_max = bc_image.max()\n",
    "    bc_image = (bc_image - bc_min) / (bc_max - bc_min)   \n",
    "    return (bc_image, bc_min, bc_max)\n",
    "\n",
    "def inv_bc_clip(image, mi, mx, lam):\n",
    "    bc_image = image * (mx - mi) + mi\n",
    "    bc_image = inv_boxcox(bc_image, lam)\n",
    "    return bc_image\n",
    "\n",
    "def normalize(in_content):\n",
    "\tin_content_abs = np.abs(in_content)\n",
    "\tin_content_norm = in_content_abs/in_content_abs.max()\n",
    "\treturn in_content_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Part(prepare&split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataset(imagetype,init,end,down_factor,snr_dB,downsampling,num_x_points,num_y_points,num_freqs):\n",
    "\n",
    "    x = np.arange(0,num_x_points,1).tolist()\n",
    "    y = np.arange(0,num_y_points,1).tolist()\n",
    "\n",
    "    images = []\n",
    "    zero_lines_idxs = []\n",
    "    counter_array = np.arange(init,end+1,1)\n",
    "\n",
    "    datapath = '../dataset/Dataset_complex/dataset_complex_'\n",
    "    for count in counter_array:\n",
    "        with open(datapath+str(count), 'rb') as data:\n",
    "            dati = pickle.load(data)\n",
    "\n",
    "        perc=10\n",
    "\n",
    "        print('')\n",
    "        print('Preparing '+datapath+str(count))\n",
    "        print('')\n",
    "\n",
    "        for i in range(len(dati)):\n",
    "            percentage= round((i/len(dati))*100,0)\n",
    "            if percentage==perc:\n",
    "                print('Percentage: '+str(perc)+'%')\n",
    "                perc = perc+10\n",
    "\n",
    "            target_img = np.array(dati[i][6])\n",
    "            input_img = np.array(dati[i][6])\n",
    "#             target_img = np.array(np.real(dati[i][6]))\n",
    "#             input_img = np.array(np.real(dati[i][6]))\n",
    "#             target_img = np.array(np.imag(dati[i][6]))\n",
    "#             input_img = np.array(np.imag(dati[i][6]))\n",
    "\n",
    "            #addition of noise\n",
    "            if snr_dB>0:\n",
    "                if i==0:\n",
    "                    print('')\n",
    "                    print('Adding '+str(snr_dB)+' dB noise to input images')\n",
    "                    print('')\n",
    "                power = np.mean(input_img ** 2)\n",
    "                var = power / (10 ** (snr_dB / 10))\n",
    "                noise = np.random.normal(0, np.sqrt(var), np.shape(input_img))\n",
    "                input_img = input_img+noise\n",
    "\n",
    "            if datapath=='./dataset/DatasetFiles/Dataset_xy/Dataset_xy_':\n",
    "                if downsampling=='random':\n",
    "                    if down_factor==2:\n",
    "                        x_sampled_list = sample(x,k=int(num_x_points*(1/down_factor)))\n",
    "\n",
    "                    else:\n",
    "                        if down_factor==4:\n",
    "                            x_sampled_list = sample(x,k=int(num_x_points*(2/down_factor)))\n",
    "                            y_sampled_list = sample(y,k=int(num_y_points*(2/down_factor)))\n",
    "\n",
    "                        else:\n",
    "                            x_sampled_list = sample(x,k=int(num_x_points*(2/down_factor)))\n",
    "                            y_sampled_list = sample(y,k=int(num_y_points*(4/down_factor)))\n",
    "\n",
    "                        y_sampled_list.sort()\n",
    "\n",
    "                    x_sampled_list.sort()\n",
    "\n",
    "                    if down_factor==2:\n",
    "                        sampled_list = x_sampled_list\n",
    "                        i=0\n",
    "                        for idx in x:\n",
    "                            if i==num_x_points*(1/down_factor):\n",
    "                                break\n",
    "                            elif idx!=sampled_list[i]:\n",
    "                                input_img[:,idx]=np.zeros(num_y_points)\n",
    "                            else:\n",
    "                                i=i+1\n",
    "                    else:\n",
    "                        sampled_list = x_sampled_list+y_sampled_list\n",
    "                        x_down_factor=down_factor/2\n",
    "\n",
    "                        i=0\n",
    "\n",
    "                        for idx in x:\n",
    "                            if i==int(num_x_points*(1/x_down_factor)):\n",
    "                                break\n",
    "                            elif idx!=sampled_list[i]:\n",
    "                                input_img[:,idx]=np.zeros(num_y_points)\n",
    "                            else:\n",
    "                                i=i+1\n",
    "                        for idy in y:\n",
    "                            if i==len(sampled_list):\n",
    "                                break\n",
    "                            elif idy!=sampled_list[i]:\n",
    "                                input_img[idy,:]=np.zeros(num_x_points)\n",
    "                            else:\n",
    "                                i=i+1\n",
    "\n",
    "                elif downsampling=='regular':\n",
    "\n",
    "                    if down_factor==2:\n",
    "                        sampled_list = x[::down_factor]\n",
    "\n",
    "                        for idx in x:\n",
    "                            if idx%down_factor!=0:\n",
    "                                input_img[:,idx]=np.zeros(num_y_points)\n",
    "\n",
    "                    else:\n",
    "                        x_down_factor = int(down_factor/2)\n",
    "                        if down_factor==4:\n",
    "                            y_down_factor = x_down_factor\n",
    "                            sampled_list = x[::x_down_factor]+y[::y_down_factor]\n",
    "                        else:\n",
    "                            y_down_factor = int(x_down_factor/2)\n",
    "                            sampled_list = x[::x_down_factor]+y[::y_down_factor]\n",
    "\n",
    "                        for idx in x:\n",
    "                            if idx%x_down_factor!=0:\n",
    "                                input_img[:,idx]=np.zeros(num_y_points)\n",
    "\n",
    "                        for idy in y:\n",
    "                            if idy%y_down_factor==0:\n",
    "                                input_img[idy,:]=np.zeros(num_x_points)\n",
    "\n",
    "                #print(sampled_list)\n",
    "\n",
    "            elif datapath=='./dataset/DatasetFiles/Dataset_yf/Dataset_yf_':\n",
    "                if downsampling=='random':\n",
    "                    sampled_list = sample(y,k=int(num_y_points*(1-1/down_factor)))\n",
    "                    sampled_list.sort()\n",
    "                    i=0\n",
    "                    for idx in y:\n",
    "                        if i==len(sampled_list):\n",
    "                            break\n",
    "                        elif idx==sampled_list[i]:\n",
    "                            input_img[idx,:]=np.zeros(num_freqs)\n",
    "                            i=i+1\n",
    "                elif downsampling=='regular':\n",
    "                    for idy in y:\n",
    "                        if idy%down_factor!=0:\n",
    "                            input_img[idy,:]=np.zeros(num_freqs)\n",
    "\n",
    "#             elif datapath=='./dataset/DatasetFiles/Dataset_xf/Dataset_xf_':\n",
    "            else:\n",
    "\n",
    "                if num_x_points<64: #it means the image is real\n",
    "                    target_img = np.array(dati[i][6][16:16+32,:])\n",
    "                    input_img = np.array(dati[i][6][16:16+32,:])\n",
    "\n",
    "                if downsampling=='random':\n",
    "                    sampled_list = sample(x,k=int(num_x_points*(1/down_factor)))\n",
    "                    sampled_list.sort()\n",
    "\n",
    "                    i=0\n",
    "                    for idx in x:\n",
    "                        if i==num_x_points*(1/down_factor):\n",
    "                            break\n",
    "                        elif idx!=sampled_list[i]:\n",
    "                            input_img[idx,:]=np.zeros(num_freqs)\n",
    "                        else:\n",
    "                            i=i+1\n",
    "\n",
    "                elif downsampling=='regular':\n",
    "                    sampled_list = x[::down_factor]\n",
    "\n",
    "                    for idx in x:\n",
    "                        if idx%down_factor!=0:\n",
    "                            input_img[idx,:]=np.zeros(num_freqs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             if imagetype!='xy' and abs(np.mean(target_img**2))>1e-10:\n",
    "            if imagetype!='xy':\n",
    "#                 print(\"np.mean(target_img**2)==\",np.mean(target_img**2))\n",
    "                images.append((input_img,target_img))\n",
    "                zero_lines_idxs.append(sampled_list)\n",
    "\n",
    "                '''plt.subplot(121), plt.title('Input xy image')\n",
    "                plt.imshow(input_img, cmap='bone', aspect='auto'), plt.colorbar()\n",
    "                plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "                plt.grid(None)\n",
    "                plt.subplot(122), plt.title('Target xy image')\n",
    "                plt.imshow(target_img, cmap='bone', aspect='auto'), plt.colorbar()\n",
    "                plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "                plt.grid(None)\n",
    "                plt.show()'''\n",
    "\n",
    "    ### ADD CHANNEL DIMENSION\n",
    "\n",
    "    print('')\n",
    "    print('Dataset ready to be splitted --> '+str(len(images))+' images')\n",
    "    print('')\n",
    "\n",
    "    images = np.array(images)\n",
    "    if datapath=='./dataset/DatasetFiles/Dataset_xf/Dataset_xf_':\n",
    "        images = images.reshape(len(images),2,num_x_points,num_freqs,1)\n",
    "    elif datapath=='./dataset/DatasetFiles/Dataset_yf/Dataset_yf_':\n",
    "        images = images.reshape(len(images),2,num_y_points,num_freqs,1)\n",
    "    elif datapath=='./dataset/DatasetFiles/Dataset_xy/Dataset_xy_':\n",
    "        images = images.reshape(len(images),2,num_y_points,num_x_points,1)\n",
    "    else:\n",
    "        images = images.reshape(len(images),2,num_x_points,num_freqs,1)\n",
    "    if isinstance(images[0][1][0][0][0], complex):\n",
    "        real = np.real(images)\n",
    "        imag = np.imag(images)\n",
    "        images = np.stack((real[:], imag[:]), axis=4)\n",
    "        \n",
    "    return images, zero_lines_idxs\n",
    "\n",
    "def splitDataset(dataset,zero_lines_idxs,batch_size,lam):\n",
    "    ### DIVIDING THE DATASET INTO TRAIN, VALIDATION AND TEST SETS\n",
    "    shuffler = np.random.permutation(len(dataset))\n",
    "#     if isinstance(dataset[0][1][0][0][0], complex):\n",
    "#         real = np.real(dataset)\n",
    "#         imag = np.imag(dataset)\n",
    "#         dataset = np.stack((real[:], imag[:]), axis=4)\n",
    "\n",
    "    dataset = np.array(dataset, dtype='float32')\n",
    "    zero_lines_idxs = np.array(zero_lines_idxs)\n",
    "\n",
    "    dataset = dataset[shuffler]\n",
    "    zero_lines_idxs = zero_lines_idxs[shuffler]\n",
    "\n",
    "    train, val, test = np.split(dataset,[int(.9 * len(dataset)),int(1 * len(dataset))])\n",
    "    print(test)\n",
    "    train_zli, val_zli, test_zli = np.split(zero_lines_idxs,[int(.9 * len(zero_lines_idxs)),int(1.0 * len(zero_lines_idxs))])\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "\n",
    "    print(\"Preparing training set \")\n",
    "    train_samples = len(train)-len(train)%batch_size\n",
    "    for idx in range(train_samples):\n",
    "        '''input_img_eq, mini, maxi = bc_clip(train[idx][0],lam)\n",
    "        target_img_eq, mint, maxt = bc_clip(train[idx][1],lam)'''\n",
    "        X_train.append(normalize(train[idx][0]))\n",
    "        Y_train.append(normalize(train[idx][1]))\n",
    "        '''X_train.append(input_img_eq)\n",
    "        Y_train.append(target_img_eq)'''\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "\n",
    "    print(\"Training sets ready :\"+str(np.shape(X_train)))\n",
    "    print('')\n",
    "\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "\n",
    "    print(\"Preparing validation set \")\n",
    "    val_samples = len(val)-len(val)%batch_size\n",
    "    for idx in range(val_samples):\n",
    "        '''input_img_eq, mini, maxi = bc_clip(val[idx][0],lam)\n",
    "        target_img_eq, mint, maxt = bc_clip(val[idx][1],lam)'''\n",
    "        X_val.append(normalize(val[idx][0]))\n",
    "        Y_val.append(normalize(val[idx][1]))\n",
    "        '''X_val.append(input_img_eq)\n",
    "        Y_val.append(target_img_eq)'''\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    Y_val = np.array(Y_val)\n",
    "\n",
    "    print(\"Validation set ready :\"+str(np.shape(X_val)))\n",
    "    print('')\n",
    "\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    X_test_noeq = []\n",
    "    Y_test_noeq = []\n",
    "    dynamics = []\n",
    "\n",
    "    print(\"Preparing test set \")\n",
    "    test_samples = len(test)-len(test)%batch_size\n",
    "    for idx in range(test_samples):\n",
    "        '''input_img_eq, mini, maxi = bc_clip(test[idx][0],lam)\n",
    "        target_img_eq, mint, maxt = bc_clip(test[idx][1],lam)'''\n",
    "        X_test.append(normalize(test[idx][0]))\n",
    "        Y_test.append(normalize(test[idx][1]))\n",
    "        '''X_test_noeq.append(test[idx][0])\n",
    "        Y_test_noeq.append(test[idx][1])\n",
    "        #dynamics.append((maxt,mint))'''\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(Y_test)\n",
    "    '''X_test_noeq = np.array(X_test_noeq)\n",
    "    Y_test_noeq = np.array(Y_test_noeq)\n",
    "    dynamics = np.array(dynamics)'''\n",
    "\n",
    "    print(\"Test set ready :\"+str(np.shape(X_test)))\n",
    "    print('')\n",
    "\n",
    "    #return X_train,Y_train,X_val,Y_val,X_test,Y_test,X_test_noeq,Y_test_noeq,dynamics\n",
    "    return X_train,Y_train,X_val,Y_val,X_test,Y_test,test_zli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial part (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing ../dataset/Dataset_complex/dataset_complex_1\n",
      "\n",
      "Percentage: 10%\n",
      "Percentage: 20%\n",
      "Percentage: 30%\n",
      "Percentage: 40%\n",
      "Percentage: 50%\n",
      "Percentage: 60%\n",
      "Percentage: 70%\n",
      "Percentage: 80%\n",
      "Percentage: 90%\n",
      "Percentage: 100%\n",
      "\n",
      "Dataset ready to be splitted --> 1632 images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    ".py args：\n",
    "\n",
    "\"\"\"\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--imagetype',type=str,required=False,default='yf')\n",
    "# parser.add_argument('--outdir',type=str,required=False,\n",
    "#     default='../ModelCheckpoint/super_res_complex_xf_2.h5')\n",
    "# parser.add_argument('--outdir_trainhistory',type=str,required=False,\n",
    "#     default='../ModelCheckpoint/th_complex_xf_2')\n",
    "# parser.add_argument('--outdir_metrics',type=str,required=False,\n",
    "#     default='../Metrics/Metrics_behaviour_complex_xf_2')\n",
    "# parser.add_argument('--outdir_plots',type=str,required=False,\n",
    "#     default='../Plots/Plot_complex_xf_2')\n",
    "# parser.add_argument('--lam',type=float,required=False,default=0.3)\n",
    "# parser.add_argument('--downsampling',type=str,required=False,\n",
    "#     default='regular')\n",
    "# parser.add_argument('--lr',type=float,required=False,default=0.0004)\n",
    "# parser.add_argument('--num_freqs',type=int,required=False,default=1024)\n",
    "# parser.add_argument('--snr',type=int,required=False,default=0)\n",
    "# parser.add_argument('--batch_size',type=int,required=False,default=1)\n",
    "# parser.add_argument('--num_x_points',type=int,required=False,default=64)\n",
    "# parser.add_argument('--num_y_points',type=int,required=False,default=16)\n",
    "# parser.add_argument('--epochs',type=int,required=False,default=1)\n",
    "# parser.add_argument('--down_factor',type=int,required=False,default=8)\n",
    "# parser.add_argument('--train_session',type=int,required=False,default=1)\n",
    "# parser.add_argument('--init_dataset_idx',type=int,required=False,default=1)\n",
    "# parser.add_argument('--final_dataset_idx',type=int,required=False,default=1)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ".ipynb args：\n",
    "\n",
    "\"\"\"\n",
    "args = easydict.EasyDict({\n",
    "    \"imagetype\": 'xf',\n",
    "    \"outdir\": '../ModelCheckpoint/super_res_complex_xf_2.h5',\n",
    "    \"outdir_trainhistory\": '../ModelCheckpoint/th_complex_xf_2',\n",
    "    \"outdir_metrics\": '../Metrics/Metrics_behaviour_complex_xf_2',\n",
    "    \"outdir_plots\": '../Plots/Plot_complex_xf_2',\n",
    "    \"lam\": 0.3,\n",
    "    \"downsampling\": 'regular',\n",
    "    \"lr\": 0.0004,\n",
    "    \"num_freqs\": 1024,\n",
    "    \"snr\": 0,\n",
    "    \"batch_size\": 1,\n",
    "    \"num_x_points\": 64,\n",
    "    \"num_y_points\": 16,\n",
    "    \"epochs\": 1,\n",
    "    \"down_factor\": 2,\n",
    "    \"train_session\": 1,      # 1 2 3\n",
    "    \"init_dataset_idx\": 1,   # 1 5 8\n",
    "    \"final_dataset_idx\": 1   # 4 7 10\n",
    "})\n",
    "\n",
    "\n",
    "#inizializza variabili globali\n",
    "num_x_points = args.num_x_points\n",
    "num_y_points = args.num_y_points\n",
    "num_freqs = args.num_freqs\n",
    "x = np.arange(0,num_x_points,1).tolist() # x-axis\n",
    "y = np.arange(0,num_y_points,1).tolist() # y-axis\n",
    "freq = np.arange(0,num_freqs,1).tolist()  #frequency axis\n",
    "\n",
    "dataset,zero_lines_idxs = prepareDataset(args.imagetype,args.init_dataset_idx,args.final_dataset_idx,args.down_factor,args.snr,args.downsampling, \n",
    "    num_x_points, num_y_points, num_freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Preparing training set \n",
      "Training sets ready :(1468, 64, 1024, 2, 1)\n",
      "\n",
      "Preparing validation set \n",
      "Validation set ready :(164, 64, 1024, 2, 1)\n",
      "\n",
      "Preparing test set \n",
      "Test set ready :(0,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_val,Y_val,X_test,Y_test,test_zli = splitDataset(dataset,zero_lines_idxs,args.batch_size,args.lam)\n",
    "# X_train = dataset[:,0,:,:,:,:]\n",
    "# Y_train = dataset[:,1,:,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compile model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model\n",
      "\n",
      "=====================first_dim: 64 =====================second_dim: 1024\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 1024, 2) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d (Reflectio (None, 66, 1026, 2)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 1024, 16) 304         reflection_padding2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 1024, 16) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_1 (Reflect (None, 66, 1026, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 1024, 16) 2320        reflection_padding2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 1024, 16) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 512, 16)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_2 (Reflect (None, 34, 514, 16)  0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 512, 32)  4640        reflection_padding2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 512, 32)  128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_3 (Reflect (None, 34, 514, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 512, 32)  9248        reflection_padding2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 512, 32)  128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 256, 32)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_4 (Reflect (None, 18, 258, 32)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 256, 64)  18496       reflection_padding2d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 256, 64)  64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_5 (Reflect (None, 18, 258, 64)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 256, 64)  36928       reflection_padding2d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 256, 64)  64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 128, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_6 (Reflect (None, 10, 130, 64)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 128, 128)  73856       reflection_padding2d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 128, 128)  32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_7 (Reflect (None, 10, 130, 128) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 128, 128)  147584      reflection_padding2d_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 128, 128)  32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 64, 128)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 64, 256)   295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 64, 256)   16          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 64, 256)   590080      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 64, 256)   16          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 128, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 128, 384)  0           up_sampling2d[0][0]              \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_8 (Reflect (None, 10, 130, 384) 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 128, 128)  442496      reflection_padding2d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 128, 128)  32          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_9 (Reflect (None, 10, 130, 128) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 128, 128)  147584      reflection_padding2d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 128, 128)  32          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 256, 128) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 256, 192) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_10 (Reflec (None, 18, 258, 192) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 256, 64)  110656      reflection_padding2d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 256, 64)  64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_11 (Reflec (None, 18, 258, 64)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 256, 64)  36928       reflection_padding2d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 256, 64)  64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 512, 64)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 512, 96)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_12 (Reflec (None, 34, 514, 96)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 512, 32)  27680       reflection_padding2d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 512, 32)  128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_13 (Reflec (None, 34, 514, 32)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 512, 32)  9248        reflection_padding2d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 512, 32)  128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 1024, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 1024, 48) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_14 (Reflec (None, 66, 1026, 48) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 1024, 16) 6928        reflection_padding2d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 1024, 16) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_15 (Reflec (None, 66, 1026, 16) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 1024, 16) 2320        reflection_padding2d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 1024, 16) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 1024, 2)  34          batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,964,450\n",
      "Trainable params: 1,963,474\n",
      "Non-trainable params: 976\n",
      "__________________________________________________________________________________________________\n",
      "Model compiled. Training model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"Compiling model\")\n",
    "    print('')\n",
    "    # Build&Compile Neural Networks\n",
    "    if args.imagetype=='xf':\n",
    "        uNet = uNet1(num_x_points,num_freqs)\n",
    "    elif args.imagetype=='yf':\n",
    "        uNet = uNet1(num_y_points,num_freqs)\n",
    "    else:\n",
    "        uNet = uNet1(num_y_points,num_x_points)\n",
    "\n",
    "    uNet.summary()\n",
    "\n",
    "    if args.train_session>1:\n",
    "        print('Loading weights')\n",
    "        uNet.load_weights(args.outdir)\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "    if args.imagetype=='xy':\n",
    "        uNet.compile(loss=mse, optimizer=opt, metrics=[NMSE, ncc])\n",
    "    elif args.imagetype=='xf':\n",
    "        uNet.compile(loss=mask_mse(args.batch_size,args.num_x_points), optimizer=opt, metrics=[NMSE, ncc])\n",
    "    elif args.imagetype=='yf':\n",
    "        uNet.compile(loss=mask_mse(args.batch_size,args.num_y_points), optimizer=opt, metrics=[NMSE, ncc])\n",
    "\n",
    "    callback = [#EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.2),\n",
    "                ModelCheckpoint(\n",
    "                    filepath=args.outdir,\n",
    "                    monitor='val_loss', verbose=1, save_best_only=True)]\n",
    "\n",
    "    print(\"Model compiled. Training model\")\n",
    "    print('')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Test\n",
    "# import math\n",
    "# # print(np.shape(dataset))\n",
    "# # print(np.shape(X_train))\n",
    "# # print(np.shape(dataset[0][1][0]))\n",
    "# # test_num =  dataset[0][1][1]\n",
    "# # print(np.shape(test_num))\n",
    "# # print(test_num)\n",
    "# # print(isinstance(dataset[0][1][0][0][0], complex))\n",
    "# # print(dataset[0][1][0][0][0])\n",
    "\n",
    "\n",
    "# # if isinstance(dataset[0][1][0][0][0], complex):\n",
    "# #     for i in range(64):\n",
    "# #         for j in range(1024):\n",
    "# #             dataset[0][1][i][j][1] = np.imag(dataset[0][1][i][j][0])\n",
    "# #             dataset[0][1][i][j][0] = np.real(dataset[0][1][i][j][0])\n",
    "# # dataset[0][1][0][0].append([np.imag(dataset[0][1][0][0][0])])\n",
    "# # array = np.concatenate((np.imag(dataset[0][1][0][0][0]), dataset[0][1][0][0][0]), axis=1)\n",
    "\n",
    "# print(dataset[0][1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# real = np.real(dataset)\n",
    "# imag = np.imag(dataset)\n",
    "\n",
    "\n",
    "# print(np.shape(dataset))\n",
    "# print(np.shape(real))\n",
    "# result = np.stack((real[:], imag[:]), axis=4)\n",
    "# print(result.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(real[0][0][0][0][0])\n",
    "# print(imag[0][0][0][0][0])\n",
    "# print(result[0][0][0][0][0][0],\" \",result[0][0][0][0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the U-net model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0][0]\n",
    "# print(np.shape(X_train))\n",
    "# print(X_train[1][0][0][0][0])\n",
    "\n",
    "X_train = X_train[:,:,:,:,0]\n",
    "Y_train = Y_train[:,:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 406/1468 [=======>......................] - ETA: 18s - loss: 5.8728e-06 - NMSE: -33.8275 - ncc: 0.9905"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### TRAINING THE U-net\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43muNet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     history = uNet.fit(X_train, Y_train, epochs=args.epochs, verbose=1, callbacks=callback,batch_size=args.batch_size)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(args\u001b[38;5;241m.\u001b[39moutdir_trainhistory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_pi:\n",
      "File \u001b[0;32m/nas/home/jcui/miniconda3/envs/thesis/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/nas/home/jcui/miniconda3/envs/thesis/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m/nas/home/jcui/miniconda3/envs/thesis/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/nas/home/jcui/miniconda3/envs/thesis/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nas/home/jcui/miniconda3/envs/thesis/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/nas/home/jcui/miniconda3/envs/thesis/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/nas/home/jcui/miniconda3/envs/thesis/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "    ### TRAINING THE U-net\n",
    "\n",
    "    history = uNet.fit(X_train, Y_train, epochs=args.epochs, verbose=1, callbacks=callback, validation_data=(X_val, Y_val),batch_size=args.batch_size)\n",
    "\n",
    "#     history = uNet.fit(X_train, Y_train, epochs=args.epochs, verbose=1, callbacks=callback,batch_size=args.batch_size)\n",
    "    with open(args.outdir_trainhistory, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ### TESTING THE U-net\n",
    "# print('')\n",
    "# print(\"Testing\")\n",
    "# score = uNet.evaluate(X_test, Y_test, verbose=1, batch_size=args.batch_size)\n",
    "# probs = uNet.predict(X_test, verbose=1, batch_size=args.batch_size)\n",
    "# print(\"score:\",score)\n",
    "# print('')\n",
    "# print(\"Custom metrics and plot results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate custom matrics and save them using pickle (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#     ### CALCULATE THE CUSTOM METRICS AND SAVE THEM USING PICKLE\n",
    "\n",
    "#     if args.imagetype=='xy':\n",
    "#         if args.down_factor==2:\n",
    "#             x_ds = np.arange(0,num_x_points,args.down_factor) # down-sampled x-axis vector\n",
    "#             y_ds = y\n",
    "#         elif args.down_factor==4:\n",
    "#             x_ds = np.arange(0,num_x_points,int(args.down_factor/2)) \n",
    "#             y_ds = np.arange(0,num_y_points,int(args.down_factor/2))\n",
    "#         else:\n",
    "#             x_ds = np.arange(0,num_x_points,int(args.down_factor/2)) \n",
    "#             y_ds = np.arange(0,num_y_points,int(args.down_factor/4))\n",
    "#     else:\n",
    "#         x_ds = np.arange(0,num_x_points,args.down_factor)\n",
    "#         y_ds = np.arange(0,num_y_points,args.down_factor)\n",
    "\n",
    "#     list_metrics = []\n",
    "#     list_plots = []\n",
    "# #     print(\"X_test shape: \",np.shape(X_test))\n",
    "# #     print(\"Y_test shape: \",np.shape(Y_test))\n",
    "# #     print(\"probs shape: \",np.shape(probs))\n",
    "#     for idx in range(len(Y_test)):\n",
    "#         down = X_test[idx][:,:,0,0] + X_test[idx][:,:,1,0]*1j\n",
    "#         ground_truth = Y_test[idx][:,:,0,0] + Y_test[idx][:,:,1,0]*1j\n",
    "#         prediction = probs[idx][:,:,0] + probs[idx][:,:,1]*1j\n",
    "# #         print(\"down shape: \",np.shape(down))\n",
    "# #         print(\"prediction shape: \",np.shape(prediction))\n",
    "# #         ground_truth = Y_test[idx][:,:,:,0] # complex \n",
    "# #         prediction = probs[idx][:] # complex\n",
    "# #         print(np.shape(probs))\n",
    "# #         print(np.shape(ground_truth),\" \",np.shape(prediction))\n",
    "#         nmse1 = nmse(ground_truth,prediction)\n",
    "#         ncc1 = NCC(ground_truth,prediction)\n",
    "\n",
    "#         zero_row_idxs = test_zli[idx]\n",
    "\n",
    "#         if args.imagetype=='xy':\n",
    "#             if args.downsampling=='random':\n",
    "\n",
    "#                 if args.down_factor==2:\n",
    "#                     ds_image = np.zeros((num_y_points,int(num_x_points/args.down_factor)))\n",
    "\n",
    "#                     zero_row_idx=0\n",
    "#                     count=0\n",
    "\n",
    "#                     for j in x:\n",
    "#                         if j==zero_row_idxs[zero_row_idx]:\n",
    "#                             ds_image[:,count] = down[:,j]\n",
    "#                             count=count+1\n",
    "#                             zero_row_idx=zero_row_idx+1\n",
    "#                         if zero_row_idx==num_x_points*(1/args.down_factor):\n",
    "#                             break\n",
    "\n",
    "#                 else:\n",
    "#                     x_ds_image = np.zeros((num_y_points,2*int(num_x_points/args.down_factor)))\n",
    "\n",
    "#                     zero_row_idx=0\n",
    "#                     count=0\n",
    "\n",
    "#                     for j in x:\n",
    "#                         if j==zero_row_idxs[zero_row_idx]:\n",
    "#                             x_ds_image[:,count] = down[:,j]\n",
    "#                             count=count+1\n",
    "#                             zero_row_idx=zero_row_idx+1\n",
    "#                         if zero_row_idx==num_x_points*(2/args.down_factor):\n",
    "#                             break\n",
    "\n",
    "#                     count=0\n",
    "\n",
    "#                     if args.down_factor==4:\n",
    "#                         ds_image = np.zeros((2*int(num_y_points/args.down_factor),2*int(num_x_points/args.down_factor)))\n",
    "\n",
    "#                     elif args.down_factor==8:\n",
    "#                         ds_image = np.zeros((4*int(num_y_points/args.down_factor),2*int(num_x_points/args.down_factor)))\n",
    "\n",
    "#                     for i in y:\n",
    "#                         if i==zero_row_idxs[zero_row_idx]:\n",
    "#                             ds_image[count,:] = x_ds_image[i,:]\n",
    "#                             count=count+1\n",
    "#                             zero_row_idx=zero_row_idx+1\n",
    "#                         if zero_row_idx==len(zero_row_idxs):\n",
    "#                             break\n",
    "\n",
    "#             elif args.downsampling=='regular':\n",
    "#                 if args.down_factor==8:\n",
    "#                     ds_image = ground_truth[::int(args.down_factor/4),::int(args.down_factor/2)]\n",
    "#                 elif args.down_factor==4:\n",
    "#                     ds_image = ground_truth[::int(args.down_factor/2),::int(args.down_factor/2)]\n",
    "#                 else:\n",
    "#                     ds_image = ground_truth[:,::args.down_factor]\n",
    "\n",
    "#             '''interp = interp2d(x_ds, y_ds, ds_image, kind='cubic')\n",
    "#             interp_image = interp(x,y)'''\n",
    "#             interp_y = resample(ds_image,num_y_points,axis=0)\n",
    "#             interp_image = resample(interp_y,num_x_points,axis=1)\n",
    "\n",
    "#         elif args.imagetype=='xf':\n",
    "\n",
    "#             if args.downsampling=='random':\n",
    "\n",
    "#                 ds_image = np.zeros((int(num_x_points/args.down_factor),num_freqs))\n",
    "\n",
    "#                 zero_row_idx=0\n",
    "#                 count=0\n",
    "\n",
    "#                 for j in x:\n",
    "#                     if j==zero_row_idxs[zero_row_idx]:\n",
    "#                         ds_image[count,:] = down[j,:]\n",
    "#                         count=count+1\n",
    "#                         zero_row_idx=zero_row_idx+1\n",
    "#                     if zero_row_idx==num_x_points*(1/args.down_factor):\n",
    "#                         break\n",
    "\n",
    "#             elif args.downsampling=='regular':\n",
    "#                     ds_image = ground_truth[::args.down_factor,:]\n",
    "\n",
    "#             '''interp = interp2d(freq, x_ds, ds_image, kind='cubic')\n",
    "#             interp_image = interp(freq,x)'''\n",
    "#             interp_image = resample(ds_image,num_x_points,axis=0)\n",
    "\n",
    "# # \t\t\tplt.subplot(141), plt.title('Target')\n",
    "# # \t\t\tplt.imshow(np.clip(ground_truth, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# # \t\t\tplt.xlabel('Freq [Hz]'), plt.ylabel('X [m]')\n",
    "# # \t\t\tplt.grid(None)\n",
    "# # \t\t\tplt.subplot(142), plt.title('U-net input')\n",
    "# # \t\t\tplt.imshow(np.clip(down, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# # \t\t\tplt.xlabel('Freq [Hz]')\n",
    "# # \t\t\tplt.grid(None)\n",
    "# # \t\t\tplt.subplot(143), plt.title('Interp input')\n",
    "# # \t\t\tplt.imshow(np.clip(ds_image, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# # \t\t\tplt.xlabel('Freq [Hz]')\n",
    "# # \t\t\tplt.grid(None)\n",
    "# # \t\t\tplt.subplot(144), plt.title('Interp output')\n",
    "# # \t\t\tplt.imshow(np.clip(interp_image, a_min=0, a_max=0.1)/0.1, cmap='Reds', aspect='auto')\n",
    "# # \t\t\tplt.xlabel('Freq [Hz]')\n",
    "# # \t\t\tplt.grid(None)\n",
    "# # \t\t\tplt.show()\n",
    "\n",
    "#         elif args.imagetype=='yf':\n",
    "#             if args.downsampling=='random':\n",
    "#                 ds_image=down[~np.all(down==0, axis=1)]\n",
    "\n",
    "#                 if len(ds_image)==num_y_points/args.down_factor-2:\n",
    "#                     ds_image = np.concatenate((np.zeros((1,num_freqs)),ds_image), 0)\n",
    "#                     ds_image = np.concatenate((ds_image,np.zeros((1,num_freqs))), 0)\n",
    "\n",
    "#                 elif len(ds_image)==num_y_points/args.down_factor-1:\n",
    "#                     if np.max(ground_truth[0,:])==0:\n",
    "#                         ds_image = np.concatenate((np.zeros((1,num_freqs)),ds_image), 0)\n",
    "\n",
    "#                     elif np.max(ground_truth[num_y_points-1,:])==0:\n",
    "#                         ds_image = np.concatenate((ds_image,np.zeros((1,num_freqs))), 0)\n",
    "\n",
    "#             elif args.downsampling=='regular':\n",
    "#                 ds_image = ground_truth[::args.down_factor,:]\n",
    "\n",
    "#             '''interp = interp2d(freq, y_ds, ds_image, kind='cubic')\n",
    "#             interp_image = interp(freq,y)'''\n",
    "#             interp_image = resample(ds_image,num_y_points,axis=0)\n",
    "\n",
    "#         nmse2 = nmse(ground_truth,interp_image)\n",
    "#         ncc2 = NCC(ground_truth,interp_image)\n",
    "#         if args.snr>0:\n",
    "#             list_metrics.append((nmse1,ncc1))\n",
    "#             list_plots.append((down,ground_truth,prediction))\n",
    "#         else:\n",
    "#             list_metrics.append((nmse1,nmse2,ncc1,ncc2))\n",
    "#             if idx<50:\n",
    "#                 list_plots.append((down,ground_truth,prediction,interp_image))\n",
    "\n",
    "#     with open(args.outdir_metrics,'wb') as output:\n",
    "#         pickle.dump(list_metrics,output)\n",
    "\n",
    "#     with open(args.outdir_plots,'wb') as output:\n",
    "#         pickle.dump(list_plots,output)\n",
    "\n",
    "#     metrics = np.array(list_metrics)\n",
    "#     metrics = metrics.transpose()\n",
    "\n",
    "#     mean_nmse_net = np.round(np.mean(metrics[0]),2)\n",
    "#     mean_nmse_interp = np.round(np.mean(metrics[1]),2)\n",
    "\n",
    "#     mean_ncc_net = np.round(np.mean(metrics[2]),2)\n",
    "#     mean_ncc_interp = np.round(np.mean(metrics[3]),2)\n",
    "\n",
    "#     std_nmse_net = np.round(np.std(metrics[0]),2)\n",
    "#     std_nmse_interp = np.round(np.std(metrics[1]),2)\n",
    "\n",
    "#     std_ncc_net = np.round(np.std(metrics[2]),2)\n",
    "#     std_ncc_interp = np.round(np.std(metrics[3]),2)\n",
    "\n",
    "#     print('================== NMSE ==================')\n",
    "#     print('U-net :  Mean = ' + str(mean_nmse_net)+' dB || Std = '+str(std_nmse_net)+' dB')\n",
    "#     print('Interp : Mean = ' + str(mean_nmse_interp)+' dB || Std = '+str(std_nmse_interp)+' dB')\n",
    "#     print('================== NCC ==================')\n",
    "#     print('U-net :  Mean = ' + str(mean_ncc_net)+' | Std = '+str(std_ncc_net))\n",
    "#     print('Interp : Mean = ' + str(mean_ncc_interp)+' || Std = '+str(std_ncc_interp))\n",
    "\n",
    "#     reset_keras(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(probs[0]))\n",
    "# print(np.shape(ground_truth),\" \",np.shape(prediction),\" \",np.shape(interp_image))\n",
    "\n",
    "# # ground_truth_test = ground_truth[0][0]\n",
    "# # prediction_test = prediction[0][0]\n",
    "# ground_truth_test = ground_truth[:,:,0]\n",
    "# prediction_test = prediction[:,:,0]\n",
    "# interp_test = interp_image[:,:,0]\n",
    "\n",
    "# print(np.shape(ground_truth_test),\" \",np.shape(prediction_test),\" \",np.shape(interp_test))\n",
    "# print(ground_truth_test,\" \",prediction_test,\" \",interp_image)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
