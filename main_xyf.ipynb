{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imort Part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAINING OF THE U-net FOR INPAINTING AND SUPER-RESOLUTION\n",
    "\n",
    "1) Train, validate and test the U-net on the available datasets:\n",
    "    - Dataset_xf\n",
    "    - Dataset_yf\n",
    "    - Dataset_xy\n",
    "   Each 2D image is normalised by the maximum before testing.\n",
    "\n",
    "2) The Dataset is divided as follows:\n",
    "    - 80% Train set\n",
    "    - 10% Validation set\n",
    "    - 10% Test set\n",
    "\n",
    "2) Both the weights of the trained network and the loss history are\n",
    "   saved with pickle, in order to both retrain the network using the wiìeight \n",
    "   of last training and to visualize losses\n",
    "\n",
    "2) Compute and save the costum metrics as: nmse, psnr\n",
    "   both for couples:\n",
    "   - (ground truth,learned image)\n",
    "   - (ground truth, interpolated image)\n",
    "   To compare performances of the U-net with respect to a classic interpolator\n",
    "\n",
    "\"\"\"\n",
    "from scipy.special import boxcox,inv_boxcox\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import keras as keras\n",
    "import keras.callbacks as cb\n",
    "from keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from Model_Unet_3D import *\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from CustomMetricsLosses import *\n",
    "from scipy.interpolate import interpn,griddata\n",
    "import argparse\n",
    "import os\n",
    "from random import sample\n",
    "from scipy.signal import resample\n",
    "\n",
    "# usa gpu con più memoria libera\n",
    "import GPUtil\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea sessione tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7917988260213868292\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7769907552\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3488515161295011492\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import clear_session\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=tf.compat.v1.ConfigProto()\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "num_x_points = 64\n",
    "num_y_points = 16\n",
    "num_dimensions = 3\n",
    "x = np.arange(0,num_x_points,1).tolist() # x-axis\n",
    "y = np.arange(0,num_y_points,1).tolist() # y-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras(sess):\n",
    "\tclear_session()\n",
    "\tsess.close()\n",
    "\n",
    "def bc_clip(tensor, lam):\n",
    "\tbc_tensor = boxcox(tensor, lam)\n",
    "\tbc_min = bc_tensor.min()\n",
    "\tbc_max = bc_tensor.max()\n",
    "\tbc_tensor = (bc_tensor - bc_min) / (bc_max - bc_min)  \n",
    "\treturn (bc_tensor, bc_min, bc_max)\n",
    "\n",
    "def inv_bc_clip(tensor, mi, mx, lam):\n",
    "    bc_tensor = tensor * (mx - mi) + mi\n",
    "    bc_tensor = inv_boxcox(bc_tensor, lam)\n",
    "    return bc_tensor\n",
    "\n",
    "def invertible_clipping(in_content, mi, mx, p):\n",
    "\t\"\"\"\n",
    "    :param in_content: data to be processed\n",
    "    :param mi: min value for sigmoid function\n",
    "    :param mx: max value for sigmoid function\n",
    "    :param p: exponent for the power function\n",
    "    :return: normalized soft clipped image\n",
    "    \"\"\"\n",
    "\timage_clip = np.zeros(in_content.shape)\n",
    "    #Forward Clipping\n",
    "\ti,j,z = np.where(in_content < mi)\n",
    "\timage_clip[i, j, z] = 1e-4 * in_content[i, j, z] + (1 - 1e-4) * mi\n",
    "\ti,j,z = np.where(in_content > mx)\n",
    "\timage_clip[i, j, z] = 1e-4 * in_content[i, j, z] + (1 - 1e-4) * mx\n",
    "\ti,j,z = np.where((in_content >= mi) & (in_content <= mx))\n",
    "\timage_clip[i, j, z] = in_content[i, j, z]\n",
    "\n",
    "\t#Forward Normalization\n",
    "\t#real_mx = 1e-4 *1 + (1 - 1e-4) * mx\n",
    "\t#image_clip_norm = image_clip/real_mx\n",
    "\timage_clip_norm = 2 * (image_clip - mi) / (mx - mi) - 1\n",
    "\n",
    "\t#Forward Power\n",
    "\timage_clip_pow = np.power(np.abs(image_clip_norm), p)\n",
    "\treturn image_clip_pow\n",
    "\n",
    "def normalize(in_content):\n",
    "\tin_content = np.abs(in_content)\n",
    "\tmax_el = in_content.max()\n",
    "\tin_content_norm = in_content/max_el\n",
    "\treturn in_content_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Part(prepare&split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataset(datapath,init,end,ds_axis,num_freqs,down_factor,snr_dB,downsampling,tensors_per_file):\n",
    "\n",
    "    tensors = []\n",
    "    zero_lines_idxs = []\n",
    "    counter_array = np.arange(init,end+1,1)\n",
    "    for count in counter_array:\n",
    "\n",
    "        with open(datapath+str(count), 'rb') as data:\n",
    "            dati = pickle.load(data)\n",
    "\n",
    "        tens_init_freq = np.arange(0,1024,num_freqs)\n",
    "        #tens_init_freq = np.arange(0,1024,int(num_freqs/2))\n",
    "\n",
    "        print('')\n",
    "        print('Preparing '+datapath+str(count))\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "        list_tensors = sample(np.arange(0,len(dati),1).tolist(),k=tensors_per_file)\n",
    "        \n",
    "        \n",
    "        #print(list_tensors)\n",
    "        \n",
    "#         print('===============count:',count)\n",
    "#         print('===============len(dati):',len(dati))\n",
    "#         print('===============list_tensors:',list_tensors)\n",
    "#         print('===============enumerate(list_tensors):',enumerate(list_tensors))\n",
    "        \n",
    "        perc=10\n",
    "        for step,tens_idx in enumerate(list_tensors):\n",
    "        #for step in range(len(dati)):\n",
    "#             print('===============step:',step,'===============tens_idx:',tens_idx)\n",
    "            percentage= round((step/len(dati))*100,0)\n",
    "            if percentage==perc:\n",
    "                print('Percentage: '+str(perc)+'%')\n",
    "                perc = perc+10\n",
    "            if step==len(dati)-1:\n",
    "                print('Percentage: 100%')\n",
    "\n",
    "            '''print(' Tensor : '+str(step))\n",
    "            print('')'''\n",
    "\n",
    "            for i,init_freq in enumerate(tens_init_freq):\n",
    "#                 print('===============i:',i,'===============init_freq:',init_freq,\">\",(1024-num_freqs))\n",
    "                if init_freq>1024-num_freqs:\n",
    "#                     print('========= if init_freq>1024-num_freqs: ======break:',init_freq,\">\",(1024-num_freqs))\n",
    "                    break\n",
    "\n",
    "                end_freq = init_freq+num_freqs\n",
    "\n",
    "                '''print('   init_freq = '+str(init_freq))\n",
    "                print('   end_freq = '+str(end_freq))\n",
    "                print('')'''\n",
    "\n",
    "                freq = np.arange(init_freq,end_freq,1)\n",
    "\n",
    "                target_tens = np.array(dati[tens_idx][5][:,:,init_freq:end_freq])\n",
    "                input_tens = np.array(dati[tens_idx][5][:,:,init_freq:end_freq])\n",
    "\n",
    "                if snr_dB>0:\n",
    "                    if step==0 and i==0:\n",
    "                        print('')\n",
    "                        print('Adding '+str(snr_dB)+' dB noise to input tensors')\n",
    "                        print('')\n",
    "                    power = np.mean(input_tens ** 2)\n",
    "                    var = power / (10 ** (snr_dB / 10))\n",
    "                    noise = np.random.normal(0, np.sqrt(var), np.shape(input_tens))\n",
    "                    input_tens = np.abs(input_tens+noise)\n",
    "\n",
    "                if ds_axis=='x':\n",
    "                    if downsampling=='random':\n",
    "                        sampled_list = sample(x,k=int(num_x_points*(1-1/down_factor)))\n",
    "                        sampled_list.sort()\n",
    "                        i=0\n",
    "                        for idx in x:\n",
    "                            if i==len(sampled_list):\n",
    "                                break\n",
    "                            elif idx==sampled_list[i]:\n",
    "                                input_tens[:,idx,:]=np.zeros((num_y_points,num_freqs))\n",
    "                                i=i+1\n",
    "                    elif downsampling=='regular':\n",
    "                        sampled_list = x[1::down_factor]\n",
    "                        for idx in x:\n",
    "                            if idx%down_factor!=0:\n",
    "                                input_tens[:,idx,:]=np.zeros((num_y_points,num_freqs))\n",
    "\n",
    "                elif ds_axis=='y':\n",
    "                    if downsampling=='random':\n",
    "                        sampled_list = sample(y,k=int(num_y_points*(1-1/down_factor)))\n",
    "                        sampled_list.sort()\n",
    "                        i=0\n",
    "                        for idy in y:\n",
    "                            if i==len(sampled_list):\n",
    "                                break\n",
    "                            elif idy==sampled_list[i]:\n",
    "                                input_tens[idy,:,:]=np.zeros((num_x_points,num_freqs))\n",
    "                                i=i+1\n",
    "                    elif downsampling=='regular':\n",
    "                        sampled_list = y[1::down_factor]\n",
    "                        for idy in y:\n",
    "                            if idy%down_factor!=0:\n",
    "                                input_tens[idy,:,:]=np.zeros((num_x_points,num_freqs))\n",
    "\n",
    "                elif ds_axis=='xy':\n",
    "                    if downsampling=='random':\n",
    "                        x_sampled_list = sample(x,k=int(num_x_points*(1-1/down_factor)))\n",
    "                        x_sampled_list.sort()\n",
    "                        if down_factor==4:\n",
    "                            y_sampled_list = sample(y,k=int(num_y_points*(1-2/down_factor)))\n",
    "                        else:\n",
    "                            y_sampled_list = sample(y,k=int(num_y_points*(1-1/down_factor)))\n",
    "                        y_sampled_list.sort()\n",
    "                        sampled_list = x_sampled_list+y_sampled_list\n",
    "\n",
    "                        i=0\n",
    "                        for idx in x:\n",
    "                            if i==num_x_points*(1-1/down_factor):\n",
    "                                break\n",
    "                            elif idx==sampled_list[i]:\n",
    "                                input_tens[:,idx,:]=np.zeros((num_y_points,num_freqs))\n",
    "                                i=i+1\n",
    "                        for idy in y:\n",
    "                            if i==len(sampled_list):\n",
    "                                break\n",
    "                            elif idy==sampled_list[i]:\n",
    "                                input_tens[idy,:,:]=np.zeros((num_x_points,num_freqs))\n",
    "                                i=i+1\n",
    "                    elif downsampling=='regular':\n",
    "                        if down_factor==4:\n",
    "                            sampled_list = x[1::down_factor]+y[1::int(down_factor/2)]\n",
    "                        else:\n",
    "                            sampled_list = x[1::down_factor]+y[1::down_factor]\n",
    "\n",
    "                        for idx in x:\n",
    "                            if idx%down_factor!=0:\n",
    "                                input_tens[:,idx,:]=np.zeros((num_y_points,num_freqs))\n",
    "                        for idy in y:\n",
    "                            if down_factor==4:\n",
    "                                if idy%(down_factor/2)!=0:\n",
    "                                    input_tens[idy,:,:]=np.zeros((num_x_points,num_freqs))\n",
    "                            else:\n",
    "                                if idy%down_factor!=0:\n",
    "                                    input_tens[idy,:,:]=np.zeros((num_x_points,num_freqs))\n",
    "\n",
    "                zero_lines_idxs.append(sampled_list)\n",
    "                tensors.append((input_tens,target_tens))\n",
    "\n",
    "                '''plt.figure(figsize=(12, 5))\n",
    "                plt.subplot(121), plt.title('Original Histogram')\n",
    "                b, bins, patches = plt.hist(target_tens.ravel(), 100)\n",
    "                plt.subplot(122), plt.title('Histogram (pow)')\n",
    "                plt.hist(target_tens_eq.ravel(), 100)\n",
    "                plt.show()\n",
    "\n",
    "                fig,(ax1,ax2) = plt.subplots(1, 2)\n",
    "                fig1 = ax1.imshow(input_tens[7,:,:],extent=[init_freq,end_freq,num_x_points,0], cmap='bone', aspect='auto')\n",
    "                fig.colorbar(fig1,ax=ax1)\n",
    "                ax1.set_xlabel('Frequency [Hz]'), ax1.set_ylabel('X [m]'), ax1.set_title('Input xf image')\n",
    "                ax1.grid(None)\n",
    "                fig2 = ax2.imshow(target_tens[7,:,:], extent=[init_freq,end_freq,num_x_points,0],cmap='bone', aspect='auto')\n",
    "                fig.colorbar(fig2,ax=ax2)\n",
    "                ax2.set_xlabel('Frequency [Hz]'), ax2.set_ylabel('X [m]'), ax2.set_title('Target xf image')\n",
    "                ax2.grid(None)\n",
    "                plt.show()\n",
    "\n",
    "                fig,(ax1,ax2) = plt.subplots(1, 2)\n",
    "                fig1 = ax1.imshow(input_tens[:,33,:],extent=[init_freq,end_freq,num_y_points,0], cmap='bone', aspect='auto')\n",
    "                fig.colorbar(fig1,ax=ax1)\n",
    "                ax1.set_xlabel('Frequency [Hz]'), ax1.set_ylabel('Y [m]'), ax1.set_title('Input yf image')\n",
    "                ax1.grid(None)\n",
    "                fig2 = ax2.imshow(target_tens[:,33,:], extent=[init_freq,end_freq,num_y_points,0], cmap='bone', aspect='auto')\n",
    "                fig.colorbar(fig2,ax=ax2)\n",
    "                ax2.set_xlabel('Frequency [Hz]'), ax2.set_ylabel('Y [m]'), ax2.set_title('Target yf image')\n",
    "                ax2.grid(None)\n",
    "                plt.show()\n",
    "\n",
    "                plt.subplot(121), plt.title('Input xy image')\n",
    "                plt.imshow(input_tens[:,:,120], cmap='bone', aspect='auto'), plt.colorbar()\n",
    "                plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "                plt.grid(None)\n",
    "                plt.subplot(122), plt.title('Target xy image')\n",
    "                plt.imshow(target_tens[:,:,120], cmap='bone', aspect='auto'), plt.colorbar()\n",
    "                plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "                plt.grid(None)\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure()\n",
    "                plt.subplot(121), plt.title('Missing FRF')\n",
    "                plt.plot(freq,input_tens[7,33,:])\n",
    "                plt.xlabel('Frequency [Hz]')\n",
    "                plt.subplot(122), plt.title('Target FRF')\n",
    "                plt.plot(freq,target_tens[7,33,:])\n",
    "                plt.xlabel('Frequency [Hz]')\n",
    "                plt.show()'''\n",
    "    print('')\n",
    "    print('Dataset ready to be splitted --> '+str(len(tensors))+' tensors')\n",
    "    print('')\n",
    "    return tensors,zero_lines_idxs\n",
    "\n",
    "def splitDataset(dataset,zero_lines_idxs,batch_size,num_freqs,pw):\n",
    "    ### DIVIDING THE DATASET INTO TRAIN, VALIDATION AND TEST SETS\n",
    "    shuffler = np.random.permutation(len(dataset))\n",
    "\n",
    "    dataset = np.array(dataset, dtype='float32')\n",
    "    zero_lines_idxs = np.array(zero_lines_idxs)\n",
    "\n",
    "    dataset = dataset[shuffler]\n",
    "    zero_lines_idxs = zero_lines_idxs[shuffler]\n",
    "\n",
    "    train, val, test = np.split(dataset,[int(.8 * len(dataset)),int(.9 * len(dataset))])\n",
    "    train_zli, val_zli, test_zli = np.split(zero_lines_idxs,[int(.8 * len(zero_lines_idxs)),int(.9 * len(zero_lines_idxs))])\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "\n",
    "    print(\"Preparing training set \")\n",
    "    train_samples = len(train)-len(train)%batch_size\n",
    "    for idx in range(train_samples):\n",
    "\n",
    "        input_tens = normalize(train[idx][0])\n",
    "        target_tens = normalize(train[idx][1])\n",
    "\n",
    "        X_train.append(input_tens)\n",
    "        Y_train.append(target_tens)\t\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "\n",
    "    X_train = X_train.reshape(len(X_train),num_y_points,num_x_points,num_freqs,1)\n",
    "    Y_train = Y_train.reshape(len(Y_train),num_y_points,num_x_points,num_freqs,1)\n",
    "\n",
    "    print(\"Training set ready --> dimensions: \"+str(np.shape(X_train)))\n",
    "    print('')\n",
    "\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "\n",
    "    print(\"Preparing validation set \")\n",
    "    val_samples = len(val)-len(val)%batch_size\n",
    "    for idx in range(val_samples):\n",
    "\n",
    "        input_tens = normalize(val[idx][0])\n",
    "        target_tens = normalize(val[idx][1])\n",
    "\n",
    "        X_val.append(input_tens)\n",
    "        Y_val.append(target_tens)\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    Y_val = np.array(Y_val)\n",
    "\n",
    "    X_val = X_val.reshape(len(X_val),num_y_points,num_x_points,num_freqs,1)\n",
    "    Y_val = Y_val.reshape(len(Y_val),num_y_points,num_x_points,num_freqs,1)\n",
    "\n",
    "    print(\"Validation set ready --> dimensions: \"+str(np.shape(X_val)))\n",
    "    print('')\n",
    "\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    low_dnmcs_tens_idxs = []\n",
    "\n",
    "    print(\"Preparing test set \")\n",
    "    test_samples = len(test)-len(test)%batch_size\n",
    "    for idx in range(test_samples):\n",
    "\n",
    "        input_tens = normalize(test[idx][0])\n",
    "        target_tens = normalize(test[idx][1])\n",
    "\n",
    "        X_test.append(input_tens)\n",
    "        Y_test.append(target_tens)\n",
    "\n",
    "        '''print(test_zli[idx])\n",
    "        fig,(ax1,ax2) = plt.subplots(1, 2)\n",
    "        fig1 = ax1.imshow(input_tens[7,:,:], cmap='bone', aspect='auto')\n",
    "        fig.colorbar(fig1,ax=ax1)\n",
    "        ax1.set_xlabel('Frequency [Hz]'), ax1.set_ylabel('X [m]'), ax1.set_title('Input xf image')\n",
    "        ax1.grid(None)\n",
    "        fig2 = ax2.imshow(target_tens[7,:,:], cmap='bone', aspect='auto')\n",
    "        fig.colorbar(fig2,ax=ax2)\n",
    "        ax2.set_xlabel('Frequency [Hz]'), ax2.set_ylabel('X [m]'), ax2.set_title('Target xf image')\n",
    "        ax2.grid(None)\n",
    "        plt.show()'''\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(Y_test)\n",
    "\n",
    "    X_test = X_test.reshape(len(X_test),num_y_points,num_x_points,num_freqs,1)\n",
    "    Y_test = Y_test.reshape(len(Y_test),num_y_points,num_x_points,num_freqs,1)\n",
    "\n",
    "    print(\"Test set ready --> dimensions: \"+str(np.shape(X_test)))\n",
    "    print('')\n",
    "\n",
    "    return X_train,Y_train,X_val,Y_val,X_test,Y_test,test_zli,low_dnmcs_tens_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial part (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing ./dataset/DatasetFiles/Dataset_xyf/Dataset_xyf_1\n",
      "\n",
      "Percentage: 10%\n",
      "Percentage: 20%\n",
      "Percentage: 30%\n",
      "Percentage: 40%\n",
      "Percentage: 50%\n",
      "Percentage: 60%\n",
      "Percentage: 70%\n",
      "Percentage: 80%\n",
      "Percentage: 90%\n",
      "Percentage: 100%\n",
      "\n",
      "Dataset ready to be splitted --> 336 tensors\n",
      "\n",
      "Preparing training set \n",
      "Training set ready --> dimensions: (268, 16, 64, 512, 1)\n",
      "\n",
      "Preparing validation set \n",
      "Validation set ready --> dimensions: (34, 16, 64, 512, 1)\n",
      "\n",
      "Preparing test set \n",
      "Test set ready --> dimensions: (34, 16, 64, 512, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    args = easydict.EasyDict({\n",
    "        \"datapath\": './dataset/DatasetFiles/Dataset_xyf/Dataset_xyf_',\n",
    "        \"outdir\": './ModelCheckpoint/3D/super_res_3D.hdf5',\n",
    "        \"outdir_trainhistory\": './ModelCheckpoint/3D/th_3D',\n",
    "        \"outdir_metrics\": './Metrics/3D/Metrics_behaviour_3D',\n",
    "        \"outdir_plots\": './Plots/3D/Plot_3D',\n",
    "        \"ds_axis\": 'x',\n",
    "        \"num_freqs\": 512,\n",
    "        \"lam\": 0.3,\n",
    "        \"down_factor\": 2,\n",
    "        \"train_session\": 1,\n",
    "        \"init_dataset_idx\": 1,\n",
    "        \"final_dataset_idx\": 1,\n",
    "        \"epochs\": 1,\n",
    "        \"lr\": 0.0004,\n",
    "        \"batch_size\": 1,\n",
    "        \"snr\": 0,\n",
    "        \"downsampling\": 'regular',\n",
    "        \"pow\": 0.7,\n",
    "        \"tensors_per_file\": 168, # 30\n",
    "})\n",
    "\n",
    "    dataset,zero_lines_idxs = prepareDataset(args.datapath,args.init_dataset_idx,args.final_dataset_idx,args.ds_axis,\n",
    "        args.num_freqs,args.down_factor,args.snr,args.downsampling,args.tensors_per_file)\n",
    "\n",
    "    X_train,Y_train,X_val,Y_val,X_test,Y_test,test_zli,low_dnmcs_tens_idxs = splitDataset(dataset,zero_lines_idxs,args.batch_size,args.num_freqs,args.pow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================Dataset=====================\n",
      "size of the X_train:  176 bytes\n",
      "type of the X_train:  <class 'numpy.ndarray'>\n",
      "shape of the X_train:  (268, 16, 64, 512, 1)\n",
      "shape of the Y_train:  (268, 16, 64, 512, 1)\n",
      "\n",
      "shape of the X_val:  (34, 16, 64, 512, 1)\n",
      "shape of the Y_val:  (34, 16, 64, 512, 1)\n",
      "\n",
      "shape of the X_test:  (34, 16, 64, 512, 1)\n",
      "shape of the Y_test:  (34, 16, 64, 512, 1)\n",
      "\n",
      "shape of the dataset:  (336, 2, 16, 64, 512)\n",
      "shape of the zero_lines_idxs:  (336, 32)\n",
      "shape of the test_zli:  (34, 32)\n",
      "num_x_points: 64\n",
      "num_y_points: 16\n",
      "low_dnmcs_tens_idxs: []\n",
      "num_freqs: 512\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "print(\"=====================Dataset=====================\")\n",
    "print(\"size of the X_train: \",sys.getsizeof(X_train),\"bytes\")\n",
    "# print(\"shape of the X_train: \",[len(a) for a in X_train])\n",
    "print(\"type of the X_train: \",type(X_train))\n",
    "print(\"shape of the X_train: \",np.shape(X_train))\n",
    "print(\"shape of the Y_train: \",np.shape(Y_train))\n",
    "\n",
    "print(\"\\nshape of the X_val: \",np.shape(X_val))\n",
    "print(\"shape of the Y_val: \",np.shape(Y_val))\n",
    "\n",
    "print(\"\\nshape of the X_test: \",np.shape(X_test))\n",
    "print(\"shape of the Y_test: \",np.shape(Y_test))\n",
    "\n",
    "print(\"\\nshape of the dataset: \",np.shape(dataset))\n",
    "print(\"shape of the zero_lines_idxs: \",np.shape(zero_lines_idxs))\n",
    "print(\"shape of the test_zli: \",np.shape(test_zli))\n",
    "# print(\"test_zli: \",test_zli)\n",
    "print(\"num_x_points:\",num_x_points)\n",
    "print(\"num_y_points:\",num_y_points)\n",
    "\n",
    "print(\"low_dnmcs_tens_idxs:\",low_dnmcs_tens_idxs)\n",
    "print(\"num_freqs:\",args.num_freqs)\n",
    "print(\"================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compile model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 16, 64, 512, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 16, 64, 512,  896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 64, 512,  64          conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 16, 64, 512,  27680       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 64, 512,  64          conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 8, 32, 256, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 8, 32, 256, 6 55360       max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 32, 256, 6 32          conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 8, 32, 256, 6 110656      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 32, 256, 6 32          conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 4, 16, 128, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 4, 16, 128, 1 221312      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 16, 128, 1 16          conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 4, 16, 128, 1 442496      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4, 16, 128, 1 16          conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 2, 8, 64, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 2, 8, 64, 256 884992      max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2, 8, 64, 256 8           conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 2, 8, 64, 256 1769728     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 2, 8, 64, 256 8           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 1, 4, 32, 256 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 1, 4, 32, 512 3539456     max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 4, 32, 512 4           conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 1, 4, 32, 512 7078400     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 4, 32, 512 4           conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d (UpSampling3D)    (None, 2, 8, 64, 512 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2, 8, 64, 768 0           up_sampling3d[0][0]              \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 2, 8, 64, 256 5308672     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 8, 64, 256 8           conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 2, 8, 64, 256 1769728     batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2, 8, 64, 256 8           conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 4, 16, 128, 2 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 16, 128, 3 0           up_sampling3d_1[0][0]            \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 4, 16, 128, 1 1327232     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 16, 128, 1 16          conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 4, 16, 128, 1 442496      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 16, 128, 1 16          conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 8, 32, 256, 1 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 32, 256, 1 0           up_sampling3d_2[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 8, 32, 256, 6 331840      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 32, 256, 6 32          conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 8, 32, 256, 6 110656      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 32, 256, 6 32          conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 16, 64, 512,  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 64, 512,  0           up_sampling3d_3[0][0]            \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 16, 64, 512,  82976       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 64, 512,  64          conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 16, 64, 512,  27680       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 64, 512,  64          conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 16, 64, 512,  33          batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 23,532,777\n",
      "Trainable params: 23,532,533\n",
      "Non-trainable params: 244\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    print(\"Compiling model\")\n",
    "\n",
    "    uNet = uNet3(args.num_freqs)\n",
    "    uNet.summary()\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "    uNet.compile(loss=mask_mse_3D(args.batch_size, args.num_freqs), optimizer=opt, metrics=[NMSE, ncc])\n",
    "\n",
    "    callback = [ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.2),\n",
    "                ModelCheckpoint(\n",
    "                    filepath=args.outdir,\n",
    "                    monitor='val_loss', verbose=1, save_best_only=True)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the U-net model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled. Training model\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mask_mse_3D.<locals>.loss at 0x7f3b506c3a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function mask_mse_3D.<locals>.loss at 0x7f3b506c3a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "268/268 [==============================] - 131s 367ms/step - loss: 0.0115 - NMSE: -11.5871 - ncc: 0.8473 - val_loss: 0.0019 - val_NMSE: 0.1649 - val_ncc: 0.1038\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00194, saving model to ./ModelCheckpoint/3D/super_res_3D.hdf5\n"
     ]
    }
   ],
   "source": [
    "    ### TRAINING THE U-net\n",
    "    \n",
    "    print(\"Model compiled. Training model\")\n",
    "    history = uNet.fit(X_train, Y_train, epochs=args.epochs, verbose=1, callbacks=callback, validation_data=(X_val, Y_val), batch_size=args.batch_size)\n",
    "\n",
    "    with open(args.outdir_trainhistory, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the model (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "34/34 [==============================] - 3s 94ms/step - loss: 0.0018 - NMSE: 0.2891 - ncc: 0.0889\n",
      "34/34 [==============================] - 4s 95ms/step\n"
     ]
    }
   ],
   "source": [
    "    ### TESTING THE U-net\n",
    "\n",
    "    print(\"Testing\")\n",
    "\n",
    "    score = uNet.evaluate(X_test, Y_test, verbose=1, batch_size=args.batch_size)\n",
    "    probs = uNet.predict(X_test, verbose=1, batch_size=args.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate custom matrics and save them using pickle (main.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom metrics and plot results\n",
      "================== NMSE ==================\n",
      "\n",
      "U-net :  Mean = 0.29 dB || Std = 0.29 dB\n",
      "Interp : Mean = -91.23 dB || Std = 11.25 dB\n",
      "\n",
      "================== NCC ==================\n",
      "\n",
      "U-net :  Mean = 0.09 || Std = 0.03\n",
      "Interp : Mean = 1.0 || Std = 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    print(\"Custom metrics and plot results\")\n",
    "    ### CALCULATE THE CUSTOM METRICS AND SAVE THEM USING PICKLE\n",
    "\n",
    "    x_ds = np.arange(0,num_x_points,args.down_factor) # down-sampled x-axis vector\n",
    "    y_ds = np.arange(0,num_y_points,args.down_factor) # down-sampled y-axis vector\n",
    "    freq = np.arange(0,args.num_freqs,1) # frequency axis\n",
    "\n",
    "    if args.ds_axis=='xy' and args.down_factor==4:\n",
    "        y_ds = np.arange(0,num_y_points,int(args.down_factor/2))\n",
    "\n",
    "    list_metrics = []\n",
    "    list_plots = []\n",
    "\n",
    "    for idx in range(len(Y_test)):\n",
    "        '''print('Tensor n°: '+str(idx))\n",
    "        print('')'''\n",
    "\n",
    "        down =  X_test[idx][:,:,:,0]\n",
    "        ground_truth = Y_test[idx][:,:,:,0]\n",
    "        prediction = probs[idx][:,:,:,0]\n",
    "\n",
    "        '''fig,(ax1,ax2,ax3,ax4) = plt.subplots(1, 4)\n",
    "        fig1 = ax1.imshow(down[7,:,:], cmap='bone', aspect='auto')\n",
    "        fig.colorbar(fig1,ax=ax1)\n",
    "        ax1.set_xlabel('Frequency [Hz]'), ax1.set_ylabel('X [m]'), ax1.set_title('Input xf image')\n",
    "        ax1.grid(None)\n",
    "        fig2 = ax2.imshow(ground_truth[7,:,:], cmap='bone', aspect='auto')\n",
    "        fig.colorbar(fig2,ax=ax2)\n",
    "        ax2.set_xlabel('Frequency [Hz]'), ax2.set_ylabel('X [m]'), ax2.set_title('Target xf image')\n",
    "        ax2.grid(None)\n",
    "        fig3 = ax3.plot(down[7,7,:]), ax3.set_xlabel('Frequency [Hz]')\n",
    "        fig4 = ax4.plot(ground_truth[7,7,:]), ax4.set_xlabel('Frequency [Hz]')\n",
    "\n",
    "        fig,(ax1,ax2) = plt.subplots(1, 2)\n",
    "        fig1 = ax1.imshow(down[:,:,100], cmap='bone', aspect='auto')\n",
    "        fig.colorbar(fig1,ax=ax1)\n",
    "        ax1.set_xlabel('Frequency [Hz]'), ax1.set_ylabel('X [m]'), ax1.set_title('Input xy image')\n",
    "        ax1.grid(None)\n",
    "        fig2 = ax2.imshow(ground_truth[:,:,100], cmap='bone', aspect='auto')\n",
    "        fig.colorbar(fig2,ax=ax2)\n",
    "        ax2.set_xlabel('Frequency [Hz]'), ax2.set_ylabel('X [m]'), ax2.set_title('Target xy image')\n",
    "        ax2.grid(None)\n",
    "        plt.show()'''\n",
    "\n",
    "        nmse1 = nmse(ground_truth,prediction)\n",
    "        ncc1 = NCC(ground_truth,prediction)\n",
    "\n",
    "        zero_row_idxs = test_zli[idx]\n",
    "\n",
    "        grid_y, grid_x, grid_freq = np.mgrid[ 0:num_y_points:1, 0:num_x_points:1, 0:args.num_freqs:1]\n",
    "\n",
    "        if args.ds_axis=='x':\n",
    "            if args.downsampling=='random':\n",
    "                ds_tensor = np.zeros((num_y_points,int(num_x_points/args.down_factor),args.num_freqs))\n",
    "\n",
    "                zero_row_idx=0\n",
    "                count=0\n",
    "\n",
    "                for i in x:\n",
    "                    if i!=zero_row_idxs[zero_row_idx]:\n",
    "                        ds_tensor[:,count,:] = down[:,i,:]\n",
    "                        count=count+1\n",
    "                    else:\n",
    "                        zero_row_idx=zero_row_idx+1\n",
    "                        if zero_row_idx==len(zero_row_idxs):\n",
    "                            break\n",
    "\n",
    "            elif args.downsampling=='regular':\n",
    "                ds_tensor = ground_truth[:,::args.down_factor,:]\n",
    "\n",
    "            '''num_points = len(x_ds)*len(y)*len(freq)\n",
    "            points = np.zeros((num_points,num_dimensions))\n",
    "            values = np.zeros((num_points))\n",
    "            count = 0\n",
    "\n",
    "            for z in range(len(y)):\n",
    "                for j in range (len(x_ds)):\n",
    "                    for i in range(len(freq)):\n",
    "                        points[count,:] = (y[z], x_ds[j], freq[i])\n",
    "                        values[count] = ds_tensor[z,j,i]\n",
    "                        count = count+1\n",
    "\n",
    "            interp_tensor = griddata(points, values, (grid_y, grid_x, grid_freq), method='nearest')'''\n",
    "\n",
    "            interp_tensor= resample(ds_tensor,num_x_points,axis=1)\n",
    "\n",
    "            '''plt.subplot(141), plt.title('Target')\n",
    "            plt.imshow(ground_truth[:,:,120], cmap='bone', aspect='auto')\n",
    "            plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "            plt.grid(None)\n",
    "            plt.subplot(142), plt.title('U-net input')\n",
    "            plt.imshow(down[:,:,120], cmap='bone', aspect='auto')\n",
    "            plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "            plt.grid(None)\n",
    "            plt.subplot(143), plt.title('Interp input')\n",
    "            plt.imshow(ds_tensor[:,:,120], cmap='bone', aspect='auto')\n",
    "            plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "            plt.grid(None)\n",
    "            plt.subplot(144), plt.title('Interp input')\n",
    "            plt.imshow(interp_tensor[:,:,120], cmap='bone', aspect='auto'), plt.colorbar()\n",
    "            plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "            plt.grid(None)\n",
    "            plt.show()'''\n",
    "\n",
    "        elif args.ds_axis=='xy':\n",
    "            if args.downsampling=='random':\n",
    "                x_ds_tensor = np.zeros((num_y_points,int(num_x_points/args.down_factor),args.num_freqs))\n",
    "\n",
    "                zero_row_idx=0\n",
    "                count=0\n",
    "\n",
    "                for j in x:\n",
    "                    if j!=zero_row_idxs[zero_row_idx]:\n",
    "                        x_ds_tensor[:,count,:] = down[:,j,:]\n",
    "                        count=count+1\n",
    "                    else:\n",
    "                        zero_row_idx=zero_row_idx+1\n",
    "                        if zero_row_idx==num_x_points*(1-1/args.down_factor):\n",
    "                            break\n",
    "                count=0\n",
    "\n",
    "                if args.down_factor==4:\n",
    "                    ds_tensor = np.zeros((int(2*num_y_points/args.down_factor),int(num_x_points/args.down_factor),args.num_freqs))\n",
    "                else:\n",
    "                    ds_tensor = np.zeros((int(num_y_points/args.down_factor),int(num_x_points/args.down_factor),args.num_freqs))\n",
    "\n",
    "                for i in y:\n",
    "                    if i!=zero_row_idxs[zero_row_idx]:\n",
    "                        ds_tensor[count,:,:] = x_ds_tensor[i,:,:]\n",
    "                        count=count+1\n",
    "                    else:\n",
    "                        zero_row_idx=zero_row_idx+1\n",
    "                        if zero_row_idx==len(zero_row_idxs):\n",
    "                            break\n",
    "            elif args.downsampling=='regular':\n",
    "                if args.down_factor==4:\n",
    "                    ds_tensor = ground_truth[::int(args.down_factor/2),::args.down_factor,:]\n",
    "                else:\n",
    "                    ds_tensor = ground_truth[::args.down_factor,::args.down_factor,:]\n",
    "\n",
    "            '''num_points = len(x_ds)*len(y_ds)*len(freq)\n",
    "            points = np.zeros((num_points,num_dimensions))\n",
    "            values = np.zeros((num_points))\n",
    "            count = 0\n",
    "\n",
    "            for z in range(len(y_ds)):\n",
    "                for j in range (len(x_ds)):\n",
    "                    for i in range(len(freq)):\n",
    "                        points[count,:] = (y_ds[z], x_ds[j], freq[i])\n",
    "                        values[count] = ds_tensor[z,j,i]\n",
    "                        count = count+1\n",
    "\n",
    "            interp_tensor = griddata(points, values, (grid_y, grid_x, grid_freq), method='nearest')'''\n",
    "\n",
    "            interp_y = resample(ds_tensor,num_y_points,axis=0)\n",
    "            interp_tensor = resample(interp_y,num_x_points,axis=1)\n",
    "\n",
    "            '''plt.subplot(141), plt.title('Target')\n",
    "            plt.imshow(ground_truth[:,:,120], cmap='bone', aspect='auto')\n",
    "            plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "            plt.grid(None)\n",
    "            plt.subplot(142), plt.title('U-net input')\n",
    "            plt.imshow(down[:,:,120], cmap='bone', aspect='auto')\n",
    "            plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "            plt.grid(None)\n",
    "            plt.subplot(143), plt.title('Interp input')\n",
    "            plt.imshow(ds_tensor[:,:,120], cmap='bone', aspect='auto')\n",
    "            plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "            plt.grid(None)\n",
    "            plt.subplot(144), plt.title('Interp output')\n",
    "            plt.imshow(interp_tensor[:,:,120], cmap='bone', aspect='auto'), plt.colorbar()\n",
    "            plt.xlabel('X [m]'), plt.ylabel('Y [m]')\n",
    "            plt.grid(None)\n",
    "            plt.show()'''\n",
    "\n",
    "        nmse2 = nmse(ground_truth,interp_tensor)\n",
    "        ncc2 = NCC(ground_truth,interp_tensor)\n",
    "\n",
    "        if args.snr>0:\n",
    "            list_metrics.append((nmse1,ncc1))\n",
    "            list_plots.append((down,ground_truth,prediction))\n",
    "        else:\n",
    "            list_metrics.append((nmse1,nmse2,ncc1,ncc2))\n",
    "            if idx<50:\n",
    "                list_plots.append((down,ground_truth,prediction,interp_tensor))\n",
    "\n",
    "    with open(args.outdir_metrics,'wb') as output:\n",
    "        pickle.dump(list_metrics,output)\n",
    "\n",
    "    with open(args.outdir_plots,'wb') as output:\n",
    "        pickle.dump(list_plots,output)\n",
    "\n",
    "    metrics = np.array(list_metrics)\n",
    "    metrics = metrics.transpose()\n",
    "\n",
    "    mean_nmse_net = round(np.mean(metrics[0]),2)\n",
    "    mean_nmse_interp = round(np.mean(metrics[1]),2)\n",
    "\n",
    "    mean_ncc_net = round(np.mean(metrics[2]),2)\n",
    "    mean_ncc_interp = round(np.mean(metrics[3]),2)\n",
    "\n",
    "    std_nmse_net = round(np.std(metrics[0]),2)\n",
    "    std_nmse_interp = round(np.std(metrics[1]),2)\n",
    "\n",
    "    std_ncc_net = round(np.std(metrics[2]),2)\n",
    "    std_ncc_interp = round(np.std(metrics[3]),2)\n",
    "\n",
    "    print('================== NMSE ==================')\n",
    "    print('')\n",
    "    print('U-net :  Mean = ' + str(mean_nmse_net)+' dB || Std = '+str(std_nmse_net)+' dB')\n",
    "    print('Interp : Mean = ' + str(mean_nmse_interp)+' dB || Std = '+str(std_nmse_interp)+' dB')\n",
    "\n",
    "    print('')\n",
    "\n",
    "    print('================== NCC ==================')\n",
    "    print('')\n",
    "    print('U-net :  Mean = ' + str(mean_ncc_net)+' || Std = '+str(std_ncc_net))\n",
    "    print('Interp : Mean = ' + str(mean_ncc_interp)+' || Std = '+str(std_ncc_interp))\n",
    "\n",
    "    print('')\n",
    "\n",
    "    reset_keras(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
