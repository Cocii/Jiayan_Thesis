{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imort Part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import boxcox\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import keras as keras\n",
    "import keras.callbacks as cb\n",
    "from keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from Model_Unet import *\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from CustomMetricsLosses import *\n",
    "from scipy.interpolate import interp2d\n",
    "import argparse\n",
    "import os\n",
    "from random import sample\n",
    "from scipy.signal import resample\n",
    "\n",
    "# usa gpu con piÃ¹ memoria libera\n",
    "import GPUtil\n",
    "import easydict\n",
    "\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"imagetype\": 'xf',\n",
    "    \"outdir\": './dataset/Dataset_complex/dataset_complex_',\n",
    "    \"outdir_plots\": './Plots/Plot_imag_xf',\n",
    "    \"lam\": 0.3,\n",
    "    \"downsampling\": 'regular',\n",
    "    \"lr\": 0.0004,\n",
    "    \"num_freqs\": 1024,\n",
    "    \"snr\": 0,\n",
    "    \"batch_size\": 1,\n",
    "    \"num_x_points\": 64,\n",
    "    \"num_y_points\": 16,\n",
    "    \"epochs\": 1,\n",
    "    \"down_factor\": 2,\n",
    "    \"train_session\": 2,      # 1 2 3\n",
    "    \"init_dataset_idx\": 1,   # 1 5 8\n",
    "    \"final_dataset_idx\": 1   # 4 7 10\n",
    "})\n",
    "#     datapath = './dataset/DatasetFiles/Dataset_'+imagetype+'/Dataset_'+imagetype+'_'\n",
    "\n",
    "#     datapath = \"../../rmalvermi/frf-interpolation-cnn/Tesi/dataset/DatasetFiles/Dataset_xf/free_violin/dataset_free_lf_xf_1_168\"\n",
    "#     datapath = \"../../rmalvermi/frf-interpolation-cnn/Tesi/dataset/DatasetFiles/Dataset_xf/free_violin/dataset_free_lf_xf_169_336\"\n",
    "#     datapath = \"../../rmalvermi/frf-interpolation-cnn/Tesi/dataset/DatasetFiles/Dataset_xf/free_violin/dataset_free_lf_xf_337_505\"\n",
    "#     datapath = \"../../rmalvermi/frf-interpolation-cnn/Tesi/dataset/DatasetFiles/Dataset_xf/free_violin/dataset_free_lf_xf_506_674\"\n",
    "#     datapath = \"../../rmalvermi/frf-interpolation-cnn/Tesi/dataset/DatasetFiles/Dataset_xf/free_violin/dataset_free_lf_xf_675_843\"\n",
    "#     datapath = \"../../rmalvermi/frf-interpolation-cnn/Tesi/dataset/DatasetFiles/Dataset_xf/free_violin/dataset_free_lf_xf_844_1012\"\n",
    "datapath = \"../../rmalvermi/frf-interpolation-cnn/Tesi/dataset/DatasetFiles/Dataset_xf/free_violin/dataset_free_lf_xf_\"\n",
    "datapath_ = [\"1_168\",\"169_336\",\"337_505\",\"506_674\",\"675_843\",\"844_1012\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct spilit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m     dati \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(data)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 0:1632  1632:2688  \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(args\u001b[38;5;241m.\u001b[39moutdir\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[43mcount\u001b[49m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_pi:\n\u001b[1;32m      8\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(dati[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1632\u001b[39m], file_pi)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "with open(datapath+datapath_[0], 'rb') as data:\n",
    "    dati = pickle.load(data)\n",
    "\n",
    "# 0:1632  1632:2688  102*16=1632    168-66=102  102-66=36  36*16=576 0:576  1st\n",
    "# 168-36=132 enough -102tensor 576:2208 that's it     2nd  3rd  \n",
    "# 132-102=30 enough -30tensor  open 3rd  2208:2688  -72 0:1152    4nd*102\n",
    "# 169-72=97  1152:2704  open 4th  102-97=5  0:80                  5th*102\n",
    "# 169-5=164 enough -102=62  80:1712     62                        6th*102\n",
    "# 62 1712:(62*16) = 1712:2704    169-40  0:640                    7th*102\n",
    "# 129 enough  -102=27    640:2272                                 8th*102\n",
    "# 2272:2704   -75   new  0:1200                                   9th*102\n",
    "# 94 1200:2704  -8  new  0:128                                    10th*102\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [59], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m###  remember!!!!! [number] 3 4 5 6\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(datapath\u001b[38;5;241m+\u001b[39m\u001b[43mdatapath_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[1;32m      3\u001b[0m     dati6 \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(data)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "###  remember!!!!! [number] 3 4 5\n",
    "with open(datapath+datapath_[5], 'rb') as data:\n",
    "    dati5 = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2704, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1504, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(dati5))\n",
    "\n",
    "tmp = []\n",
    "tmp = dati5[1200:2704]\n",
    "\n",
    "np.shape(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### remember!!!! str() 4 5  6  7  8  9\n",
    "\n",
    "with open(args.outdir+str(10), 'wb') as file_pi:\n",
    "    pickle.dump(tmp, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_orignal = 6\n",
    "count = 1\n",
    "divid = 102\n",
    "tensor_size = 16\n",
    "for i in datapath_:\n",
    "    tmp = []\n",
    "    with open(datapath + i, 'rb') as data:\n",
    "        dati = pickle.load(data)\n",
    "    for j in range(168): #0-167\n",
    "        \n",
    "        tmp.append(dati[j*tensor_size:(j+1)*tensor_size]) #0-15 16-31\n",
    "        \n",
    "        if len(tmp)== divid*tensor_size: #full of 10%\n",
    "            with open(args.outdir+str(count), 'wb') as file_pi:\n",
    "                pickle.dump(tmp, file_pi)\n",
    "        tmp = [] # del tmp\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(datapath+datapath_[1])\n",
    "print(len(dati))\n",
    "print(np.shape(dati[:][0]))\n",
    "print(dati[16*102-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "for j in range(100):\n",
    "    with open(args.outdir+str(count), 'wb') as file_pi:\n",
    "        pickle.dump(\"0123456789\", file_pi)\n",
    "\n",
    "print(args.outdir+str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(datii[0:3])\n",
    "print(datii[3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datapath + datapath_[1], 'rb') as data:\n",
    "    dati = pickle.load(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del dati\n",
    "gc.collect()\n",
    "# gc.enable()\n",
    "# gc.disable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
